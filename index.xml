<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My bits</title>
    <link>http://lpantano.github.io/</link>
      <atom:link href="http://lpantano.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>My bits</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 04 Feb 2026 12:00:00 -0400</lastBuildDate>
    <image>
      <url>http://lpantano.github.io/media/icon_hu_518ecd45d9711c5b.png</url>
      <title>My bits</title>
      <link>http://lpantano.github.io/</link>
    </image>
    
    <item>
      <title>Why I Built My Own Running Dashboard</title>
      <link>http://lpantano.github.io/post/2026/2026-02-04-training-dashboard-long-term-data/</link>
      <pubDate>Wed, 04 Feb 2026 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2026/2026-02-04-training-dashboard-long-term-data/</guid>
      <description>&lt;p&gt;Your watch buzzes. &amp;ldquo;Congratulations on your fastest 5K this month!&amp;rdquo;&lt;/p&gt;
&lt;p&gt;But you don&amp;rsquo;t feel faster. And last month, you had three &amp;ldquo;fastest&amp;rdquo; runs that contradicted each other.&lt;/p&gt;
&lt;p&gt;I kept getting these notifications. Weekly summaries told me I was improving. Or declining. Or both, depending on which metric the app decided mattered that week.&lt;/p&gt;
&lt;p&gt;The numbers existed. But they meant nothing without context.&lt;/p&gt;
&lt;p&gt;So I built my own dashboard to see what was actually happening.&lt;/p&gt;
&lt;p&gt;Take a &lt;a href=&#34;https://run-training-activities.netlify.app/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;look&lt;/a&gt; ➡️.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2026/2026-02-04-training-dashboard-long-term-data/webapp_hu_3a375238f7aa5c96.webp 400w,
               /post/2026/2026-02-04-training-dashboard-long-term-data/webapp_hu_2c890dc1d0215c52.webp 760w,
               /post/2026/2026-02-04-training-dashboard-long-term-data/webapp_hu_de8eff785ab2dcbf.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2026/2026-02-04-training-dashboard-long-term-data/webapp_hu_3a375238f7aa5c96.webp&#34;
               width=&#34;760&#34;
               height=&#34;543&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;the-problem-with-fitness-apps&#34;&gt;The Problem With Fitness Apps&lt;/h2&gt;
&lt;p&gt;Fitness apps celebrate individual achievements. A personal record. A streak maintained. A badge earned.&lt;/p&gt;
&lt;p&gt;They show weekly summaries that create false urgency. Up 10% from last week feels like progress. Down 5% feels like failure.&lt;/p&gt;
&lt;p&gt;But fitness doesn&amp;rsquo;t work on weekly cycles. Your body adapts over months, not days, or even years.&lt;/p&gt;
&lt;p&gt;Individual run metrics mean nothing without seeing the bigger picture over time. Context matters more than numbers.&lt;/p&gt;
&lt;h2 id=&#34;what-i-wanted&#34;&gt;What I Wanted&lt;/h2&gt;
&lt;p&gt;I started following a structured training program (&lt;a href=&#34;https://tacticmethod.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tactic Method&lt;/a&gt; with coach Alex Parker). Run-walk intervals. Progressive distance. Specific pace targets.&lt;/p&gt;
&lt;p&gt;I wanted to answer one question: Is this structured approach actually working?&lt;/p&gt;
&lt;p&gt;Not based on how I felt after one run. Not based on weekly summaries that changed with the weather.&lt;/p&gt;
&lt;p&gt;Based on months of data showing whether the effort was producing results.&lt;/p&gt;
&lt;p&gt;And I wanted to own my data. Not pay for premium features to see insights about my own body—insights I can&amp;rsquo;t even fully control.&lt;/p&gt;
&lt;h2 id=&#34;what-i-built&#34;&gt;What I Built&lt;/h2&gt;
&lt;p&gt;I created a dashboard that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downloads my Garmin FIT files automatically&lt;/li&gt;
&lt;li&gt;Tracks time, distance, pace, and heart rate across all runs&lt;/li&gt;
&lt;li&gt;Visualizes trends over months with run/walk intervals separated&lt;/li&gt;
&lt;li&gt;Shows training events and phases marked on the timeline&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The technical stack: Python for data extraction, React with Plotly for visualization. I&amp;rsquo;m a scientist who codes for data analysis, so I adapted familiar tools to a new domain.&lt;/p&gt;
&lt;p&gt;Not a polished product. A working tool to see patterns.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2026/2026-02-04-training-dashboard-long-term-data/metrics_hu_632b96230d8a9ed6.webp 400w,
               /post/2026/2026-02-04-training-dashboard-long-term-data/metrics_hu_586167745dfa751.webp 760w,
               /post/2026/2026-02-04-training-dashboard-long-term-data/metrics_hu_71b63463b86c6d31.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2026/2026-02-04-training-dashboard-long-term-data/metrics_hu_632b96230d8a9ed6.webp&#34;
               width=&#34;760&#34;
               height=&#34;193&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2026/2026-02-04-training-dashboard-long-term-data/distance_hu_9442ee62987aafe9.webp 400w,
               /post/2026/2026-02-04-training-dashboard-long-term-data/distance_hu_a36f3d558ee0d40b.webp 760w,
               /post/2026/2026-02-04-training-dashboard-long-term-data/distance_hu_b1fd87df8d09bd7a.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2026/2026-02-04-training-dashboard-long-term-data/distance_hu_9442ee62987aafe9.webp&#34;
               width=&#34;760&#34;
               height=&#34;421&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;what-i-learned&#34;&gt;What I Learned&lt;/h2&gt;
&lt;h3 id=&#34;1-numbers-without-context-are-noise&#34;&gt;1. Numbers Without Context Are Noise&lt;/h3&gt;
&lt;p&gt;That &amp;ldquo;slow&amp;rdquo; run last Tuesday? Probably faster than any run you did six months ago.&lt;/p&gt;
&lt;p&gt;Your watch tells you about one data point. The dashboard shows whether that point is part of an upward trend, a plateau, or normal variation.&lt;/p&gt;
&lt;p&gt;Single metrics mean nothing. Patterns over time mean everything.&lt;/p&gt;
&lt;h3 id=&#34;2-week-to-week-progress-is-a-myth&#34;&gt;2. Week-to-Week Progress Is a Myth&lt;/h3&gt;
&lt;p&gt;My data revealed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Big improvements at first&lt;/li&gt;
&lt;li&gt;Some plateauing for a while&lt;/li&gt;
&lt;li&gt;A hard time after an injury&lt;/li&gt;
&lt;li&gt;Overall, still improving&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Apps want you to believe weekly progress is linear. The data shows it&amp;rsquo;s messy, inconsistent, and happens in waves.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/PMC6492765/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Research shows&lt;/a&gt; that structured training produces measurable improvements at 12-week intervals. Not weekly. Not even monthly in most cases.&lt;/p&gt;
&lt;p&gt;Week-to-week numbers are all over the place. That&amp;rsquo;s normal. That&amp;rsquo;s adaptation.&lt;/p&gt;
&lt;h3 id=&#34;3-structured-training-shows-up-in-data&#34;&gt;3. Structured Training Shows Up in Data&lt;/h3&gt;
&lt;p&gt;When I started following the Tactic Method program, I could see the changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distance trend line slope increased&lt;/li&gt;
&lt;li&gt;Run and walk interval paces became more consistent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not after one week. After months.&lt;/p&gt;
&lt;p&gt;It is said that structured, periodized training programs are more effective than unstructured running.&lt;/p&gt;
&lt;p&gt;My data matched this.&lt;/p&gt;
&lt;h3 id=&#34;4-seeing-accumulation-keeps-you-going&#34;&gt;4. Seeing Accumulation Keeps You Going&lt;/h3&gt;
&lt;p&gt;This was the unexpected benefit.&lt;/p&gt;
&lt;p&gt;The most powerful insight wasn&amp;rsquo;t about trends or training effectiveness. It was seeing the pile of work already done.&lt;/p&gt;
&lt;p&gt;When energy is low and motivation fades, the dashboard doesn&amp;rsquo;t show a streak to maintain or a goal to chase. It shows months of accumulated effort. I&amp;rsquo;m at 210.6 kWh—I could power approximately 80–100 homes (maybe not at -20 °C; if you know what I&amp;rsquo;m talking about, I&amp;rsquo;m sorry; if not, you&amp;rsquo;re lucky).&lt;/p&gt;
&lt;p&gt;Evidence: you&amp;rsquo;ve already done this much. You can keep going.&lt;/p&gt;
&lt;p&gt;Apps celebrate streaks because they want daily engagement. This celebrates accumulation because it shows long-term commitment.&lt;/p&gt;
&lt;p&gt;The difference matters when you need a push to get out the door.&lt;/p&gt;
&lt;h3 id=&#34;5-you-can-trust-the-long-game&#34;&gt;5. You Can Trust the Long Game&lt;/h3&gt;
&lt;p&gt;Apps want you to check daily.&lt;/p&gt;
&lt;p&gt;Real fitness happens slowly.&lt;/p&gt;
&lt;p&gt;The monthly view shows what daily anxiety misses: whether your training is actually working.&lt;/p&gt;
&lt;h2 id=&#34;how-you-can-do-this&#34;&gt;How You Can Do This&lt;/h2&gt;
&lt;p&gt;Not a full tutorial, but guidance:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Want help?&lt;/strong&gt; If you have Garmin data and want something similar, reach out. I&amp;rsquo;m offering to help set this up for others who want to see their training in context.&lt;/p&gt;
&lt;p&gt;Yes, there&amp;rsquo;s technical setup. But between AI tools and my offer to help, you have support to figure it out.&lt;/p&gt;
&lt;h3 id=&#34;get-your-data&#34;&gt;Get Your Data&lt;/h3&gt;
&lt;p&gt;Garmin lets you download FIT files from your activities. These contain all the metrics your watch records during runs.&lt;/p&gt;
&lt;h3 id=&#34;choose-your-tools&#34;&gt;Choose Your Tools&lt;/h3&gt;
&lt;p&gt;I used Python and React because I&amp;rsquo;m comfortable with data analysis. But tools don&amp;rsquo;t matter as much as seeing patterns.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re not comfortable with code, AI tools like Claude or GitHub Copilot can bridge the gap. They can explain code, suggest modifications, and help you troubleshoot errors.&lt;/p&gt;
&lt;p&gt;The goal is visualization, not perfection.&lt;/p&gt;
&lt;h3 id=&#34;start-simple&#34;&gt;Start Simple&lt;/h3&gt;
&lt;p&gt;Pick one metric that matters to you. Distance. Pace. Heart rate. Track it over time.&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t try to build everything at once.&lt;/p&gt;
&lt;h3 id=&#34;be-patient&#34;&gt;Be Patient&lt;/h3&gt;
&lt;p&gt;You need months of data to see meaningful trends. Three months minimum. Six months better.&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t an instant gratification project.&lt;/p&gt;
&lt;h3 id=&#34;use-my-code-as-a-starting-point&#34;&gt;Use My Code as a Starting Point&lt;/h3&gt;
&lt;p&gt;I&amp;rsquo;ve shared the project on &lt;a href=&#34;https://github.com/lpantano/run-training-dashboard&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;. It&amp;rsquo;s not a finished product. It&amp;rsquo;s a foundation you can customize.&lt;/p&gt;
&lt;h3 id=&#34;ai-tools-can-help&#34;&gt;AI Tools Can Help&lt;/h3&gt;
&lt;p&gt;Don&amp;rsquo;t let the code intimidate you. Tools like Claude or GitHub Copilot can help you understand and modify the code.&lt;/p&gt;
&lt;p&gt;Ask them: &amp;ldquo;Explain what this function does.&amp;rdquo; Or: &amp;ldquo;How do I change this to track weekly averages instead of daily runs?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;These AI assistants make working with code more accessible. You don&amp;rsquo;t need to be a programmer to adapt this dashboard to your needs.&lt;/p&gt;
&lt;h2 id=&#34;the-real-insight&#34;&gt;The Real Insight&lt;/h2&gt;
&lt;p&gt;Fitness apps are designed to keep you engaged daily. Your body improves monthly.&lt;/p&gt;
&lt;p&gt;The best training insight isn&amp;rsquo;t from one run. It&amp;rsquo;s from seeing six months of context that reveals whether your effort is actually working.&lt;/p&gt;
&lt;p&gt;And when motivation dips, it&amp;rsquo;s not another badge you need. It&amp;rsquo;s seeing the work you&amp;rsquo;ve already accumulated.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s what keeps you going.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;try-it-yourself&#34;&gt;Try It Yourself&lt;/h2&gt;
&lt;p&gt;Start by exporting your own data and looking at it. Not through an app&amp;rsquo;s filtered view. Just the raw patterns over time.&lt;/p&gt;
&lt;p&gt;What might you discover in your own training?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Project Repository&lt;/strong&gt;: &lt;a href=&#34;https://github.com/lpantano/run-training-dashboard&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;run-training-dashboard&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Want help setting this up?&lt;/strong&gt; Contact me through &lt;a href=&#34;https://www.instagram.com/lorena.pantano/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Instagram&lt;/a&gt; or my &lt;a href=&#34;https://www.linkedin.com/in/lpantano/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LinkedIn&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Systematic Paper Reviews with Claude Custom Commands/Skills</title>
      <link>http://lpantano.github.io/tutorials/2026-01-28-systematic-paper-reviews-with-claude-custom-commandsskills/</link>
      <pubDate>Wed, 28 Jan 2026 22:20:16 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-28-systematic-paper-reviews-with-claude-custom-commandsskills/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/YZry3CwDwAw?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Reviewing 100+ papers for Health Integrity Project taught me: consistency beats speed. Custom AI commands now run identical evaluations every time—same conflict checks, same quality criteria, same workflow.&lt;/p&gt;
&lt;p&gt;Result: 30min reviews, zero missed steps, reproducible standards. Works for any systematic workflow you repeat.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://decodingdata.substack.com/p/systematic-paper-reviews-with-claude&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://decodingdata.substack.com/p/systematic-paper-reviews-with-claude&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=YZry3CwDwAw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Systematic Paper Reviews with Claude Custom Commands</title>
      <link>http://lpantano.github.io/post/2026/2026-01-28-claude-custom-commands-paper-review/</link>
      <pubDate>Wed, 28 Jan 2026 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2026/2026-01-28-claude-custom-commands-paper-review/</guid>
      <description>&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/YZry3CwDwAw?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;em&gt;Note: Claude now calls custom commands &amp;ldquo;skills&amp;rdquo; - the functionality is identical, just renamed. This post uses the original &amp;ldquo;custom commands&amp;rdquo; terminology from the video.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-problem-inconsistent-paper-reviews&#34;&gt;The Problem: Inconsistent Paper Reviews&lt;/h2&gt;
&lt;p&gt;I review hundreds of scientific papers for the &lt;a href=&#34;https://healthintegrityproject.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Health Integrity Project&lt;/a&gt;. We evaluate health claims—things you hear everywhere, like &amp;ldquo;Red raspberry leaf shortens labor&amp;rdquo;—and determine if scientific evidence supports them.&lt;/p&gt;
&lt;p&gt;The challenge? Consistency.&lt;/p&gt;
&lt;p&gt;Manual reviews take 30 minutes to 2 hours per paper. I might check for conflicts of interest thoroughly in one review, then forget in the next. Focus on statistical methods in one paper, skip bias assessment in another. My criteria shift paper to paper.&lt;/p&gt;
&lt;p&gt;This inconsistency doesn&amp;rsquo;t just waste time—it undermines scientific validity. If evaluation criteria change between papers, the entire project loses credibility.&lt;/p&gt;
&lt;h2 id=&#34;the-solution-claude-custom-commands&#34;&gt;The Solution: Claude Custom Commands&lt;/h2&gt;
&lt;p&gt;Claude custom commands tell the AI model exactly how to handle a specific task. I created a command that runs the same evaluation workflow every single time.&lt;/p&gt;
&lt;p&gt;The workflow asks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are there conflicts of interest?&lt;/li&gt;
&lt;li&gt;Is this a valid study type (not narrative reviews)?&lt;/li&gt;
&lt;li&gt;Is the control group adequate?&lt;/li&gt;
&lt;li&gt;What biases exist?&lt;/li&gt;
&lt;li&gt;Do results align with the claim?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each paper goes through identical steps. Nothing gets skipped.&lt;/p&gt;
&lt;h2 id=&#34;how-it-works&#34;&gt;How It Works&lt;/h2&gt;
&lt;p&gt;A custom command is a markdown file in your project folder (&lt;code&gt;.claude/commands/&lt;/code&gt;). Mine is called &lt;code&gt;review-paper.md&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;basic-structure&#34;&gt;Basic Structure&lt;/h3&gt;
&lt;p&gt;Every custom command has three parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt;: What you provide&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: What Claude should do&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output format&lt;/strong&gt;: How results should look&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here&amp;rsquo;s the minimal markdown structure:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;# Command Name

## Input
- Item 1 (e.g., paper location)
- Item 2 (e.g., claim to evaluate)

## Task
Step-by-step instructions for Claude to follow

## Output Format
How you want results structured
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;my-paper-review-workflow&#34;&gt;My Paper Review Workflow&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Step 1: Validation Screen
- Check conflict of interest
- Identify study type
- Flag narrative reviews or meta-analyses
- Output: VALID or INVALID with reasons

## Step 2: Quality Assessment
- Evaluate control groups
- Assess statistical methods
- Identify biases
- Output: Quality rating with evidence

## Step 3: Result Alignment
- Compare study results to claim
- Determine if supporting or contradicting
- Output: Category recommendation
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;real-example-raspberry-leaf-study&#34;&gt;Real Example: Raspberry Leaf Study&lt;/h2&gt;
&lt;p&gt;I run the command: &lt;code&gt;/review-paper&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Claude asks for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paper location&lt;/li&gt;
&lt;li&gt;Claim being evaluated&lt;/li&gt;
&lt;li&gt;Paper position (supporting or contradicting)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I provide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paper: &lt;code&gt;raspberry-study.pdf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Claim: &amp;ldquo;Red raspberry leaf shortens labor and helps induce birth&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Position: Supporting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Claude starts the evaluation:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1 Results:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Funding: Company involvement noted, but primary funding independent&lt;/li&gt;
&lt;li&gt;Study type: Human clinical trial (valid)&lt;/li&gt;
&lt;li&gt;No narrative meta-analysis&lt;/li&gt;
&lt;li&gt;Status: Proceed to quality check&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 2 Results:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Control group: Present&lt;/li&gt;
&lt;li&gt;Statistical methods: Adequate sample size, appropriate tests&lt;/li&gt;
&lt;li&gt;Biases: Selection bias possible (self-reported outcomes)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 3 Results:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Study results: No significant difference in labor duration&lt;/li&gt;
&lt;li&gt;Alignment with claim: CONTRADICTS&lt;/li&gt;
&lt;li&gt;Category: Misinformation (claim unsupported by results)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At each step, I can interact: &amp;ldquo;Dig deeper into selection bias&amp;rdquo; or &amp;ldquo;Show exact quote about labor duration from paper.&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;beyond-paper-reviews&#34;&gt;Beyond Paper Reviews&lt;/h2&gt;
&lt;p&gt;Custom commands work for any repeated workflow.&lt;/p&gt;
&lt;p&gt;Example for bioinformatics:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;Command: /optimize-nextflow

Input: Pipeline directory

Task:
1. Analyze resource usage from execution reports
2. Calculate actual vs requested CPU/memory
3. Ignore failed jobs
4. Generate updated resource config
5. Optional: Update nextflow.config

Output: Resource optimization recommendations
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Time savings&lt;/strong&gt;: Reviews that took 1-2 hours now take 30 minutes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Same questions, same order, every paper.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thoroughness&lt;/strong&gt;: Nothing gets forgotten or skipped.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transparency&lt;/strong&gt;: The workflow is documented and repeatable.&lt;/p&gt;
&lt;p&gt;The custom command doesn&amp;rsquo;t replace my judgment—it retrieves information and ensures I evaluate every paper the same way. I still make final decisions. I still dig deeper when needed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What custom commands can&amp;rsquo;t do&lt;/strong&gt;: Make subjective quality judgments, understand context outside the paper, or catch every nuance in complex statistical methods. They work best for structured, repeatable workflows where the steps are clear.&lt;/p&gt;
&lt;p&gt;But I never miss conflict of interest checks again. I never forget to assess control groups. The baseline evaluation happens consistently.&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Find a workflow you repeat frequently&lt;/li&gt;
&lt;li&gt;Document the steps&lt;/li&gt;
&lt;li&gt;Define input, task, and output format&lt;/li&gt;
&lt;li&gt;Create a markdown file in &lt;code&gt;.claude/commands/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Test and refine&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Start simple. Even basic workflows benefit from automation.&lt;/p&gt;
&lt;p&gt;The goal isn&amp;rsquo;t to hand everything to AI. It&amp;rsquo;s to ensure your systematic processes stay systematic.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Resources:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://healthintegrityproject.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Health Integrity Project&lt;/a&gt; - Evidence-based health claim evaluation&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://code.claude.com/docs/en/skills&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Claude Custom Commands/skills Documentation&lt;/a&gt; - How to create your own commands&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://healthintegrityproject.org/workflow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Health Integrity Review Workflow&lt;/a&gt; - Our paper evaluation process&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Have you tried custom commands for your repeated workflows? What tasks would benefit from systematic automation in your work?&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bringing IGV webapp to Your Cloud Workspace in Seqera</title>
      <link>http://lpantano.github.io/tutorials/2026-01-21-bringing-igv-webapp-to-your-cloud-workspace-in-seqera/</link>
      <pubDate>Wed, 21 Jan 2026 21:42:07 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-21-bringing-igv-webapp-to-your-cloud-workspace-in-seqera/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/eWHCsjd30_A?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Read Post: &lt;a href=&#34;https://lpantano.github.io/post/2026/2026-01-16-igv-cloud-visualization/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://lpantano.github.io/post/2026/2026-01-16-igv-cloud-visualization/&lt;/a&gt;
Subscribe: &lt;a href=&#34;https://decodingdata.substack.com/s/data-at-scale&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://decodingdata.substack.com/s/data-at-scale&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You just ran a genomic pipeline that generated 50GB of BAM files in the cloud. Now you need to check alignment quality. Do you really have to download everything to run IGV locally? Switch virtual machines to load the files? Write code to generate static visuals?&lt;/p&gt;
&lt;p&gt;This integration brings IGV directly to your cloud workspace with automatic track discovery. It scans your storage, finds all genomic files, and presents them in a ready-to-load menu. No downloads, no file paths, no manual configuration.&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=eWHCsjd30_A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bringing IGV webapp to Your Cloud Workspace in Seqera</title>
      <link>http://lpantano.github.io/post/2026/2026-01-16-igv-cloud-visualization/</link>
      <pubDate>Fri, 16 Jan 2026 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2026/2026-01-16-igv-cloud-visualization/</guid>
      <description>&lt;p&gt;You just ran a genomic pipeline that generated 50GB of BAM files in the cloud. Now you need to check alignment quality. Do you really have to download everything to run IGV locally? Switch virtual machines to load the files? Write code to generate static visuals?&lt;/p&gt;
&lt;p&gt;This integration brings IGV directly to your cloud workspace with &lt;strong&gt;automatic track discovery&lt;/strong&gt;. It scans your storage, finds all genomic files, and presents them in a ready-to-load menu. No downloads, no file paths, no manual configuration.&lt;/p&gt;
&lt;h2 id=&#34;the-workflow-gap&#34;&gt;The Workflow Gap&lt;/h2&gt;
&lt;p&gt;Analysis happens in the cloud. Fast compute, scalable storage, pipelines that finish overnight.&lt;/p&gt;
&lt;p&gt;Visualization happens separately or requires coding. Manual downloads or transfers, disk space constraints, waiting for transfers to complete, changing environments.&lt;/p&gt;
&lt;p&gt;This gap slows iteration. It wastes time. And it&amp;rsquo;s fixable.&lt;/p&gt;
&lt;h2 id=&#34;what-cloud-native-visualization-looks-like&#34;&gt;What Cloud-Native Visualization Looks Like&lt;/h2&gt;
&lt;p&gt;I built an integration that runs IGV as a web app directly in Seqera workspaces. It connects to the same cloud storage your pipelines write to. It automatically discovers all genomic files. Zero downloads, zero manual file loading.&lt;/p&gt;
&lt;p&gt;Other solutions exist—desktop IGV in Studios or Python notebooks for programmatic visualization. These work, but they&amp;rsquo;re not seamless. Desktop IGV still requires manual file path configuration. Notebooks require coding for every view. This approach eliminates both friction points.&lt;/p&gt;
&lt;h2 id=&#34;how-it-works&#34;&gt;How It Works&lt;/h2&gt;
&lt;p&gt;The container combines IGV web app with Seqera&amp;rsquo;s connect-client. The connect-client uses FUSE to mount cloud storage, making remote files appear local to IGV.&lt;/p&gt;
&lt;p&gt;A startup script &lt;strong&gt;scans&lt;/strong&gt; mounted directories for genomic files—BAM, CRAM, VCF, BED, BigWig, anything IGV can read. It detects file formats, checks for index files, and generates a track catalog. IGV reads this catalog and populates a custom &amp;ldquo;Auto-discovered Tracks&amp;rdquo; menu.&lt;/p&gt;
&lt;p&gt;The visualization tool comes to where data already lives.&lt;/p&gt;
&lt;h2 id=&#34;what-this-looks-like-in-practice&#34;&gt;What This Looks Like in Practice&lt;/h2&gt;
&lt;p&gt;Launch the IGV Studio from your Seqera interface. Your browser opens with the IGV web app.&lt;/p&gt;
&lt;p&gt;Click Tracks → Auto-discovered Tracks. See a table of all your BAM files, VCF variants, coverage tracks—everything in your mounted storage.&lt;/p&gt;
&lt;p&gt;Click to load. Instant visualization.&lt;/p&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Skip the download/coding wait.&lt;/strong&gt; Checking alignments after a pipeline run no longer means waiting to transfer data or coding.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stop duplicating storage.&lt;/strong&gt; No local copies means hundreds of GB saved per researcher.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Share results faster.&lt;/strong&gt; Send a browser URL instead of transferring massive files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Onboard easier.&lt;/strong&gt; New team members don&amp;rsquo;t need complex local setups. They click a link and start viewing data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Improve reproducibility.&lt;/strong&gt; Everyone views the same authoritative data source in cloud storage, not their own potentially outdated local copies.&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Important context:&lt;/strong&gt; This solution is specifically for Seqera Platform users. If you&amp;rsquo;re using other platforms like Terra, AnVIL, Galaxy, or DNAnexus, they have their own approaches to interactive visualization. This implementation leverages Seqera&amp;rsquo;s Studios feature and connect-client architecture.&lt;/p&gt;
&lt;p&gt;The full implementation is open source in the &lt;a href=&#34;https://github.com/lpantano/custom-studios-examples/tree/master/igv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seqera custom studios examples repository&lt;/a&gt;. You&amp;rsquo;ll find:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complete Dockerfile with multi-stage build&lt;/li&gt;
&lt;li&gt;Automatic track discovery script&lt;/li&gt;
&lt;li&gt;Deployment documentation&lt;/li&gt;
&lt;li&gt;Configuration examples&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Maturity note:&lt;/strong&gt; This is a proof of concept tested on several datasets. It demonstrates the pattern and should help you get started, but expect to adapt it for production use. Test thoroughly with your own data and file structures.&lt;/p&gt;
&lt;p&gt;The code is customizable. Adapt the track discovery logic for your file naming conventions. Change the reference genome. Add authentication if needed.&lt;/p&gt;
&lt;h2 id=&#34;the-broader-pattern&#34;&gt;The Broader Pattern&lt;/h2&gt;
&lt;p&gt;Cloud-native analysis means rethinking entire workflows, not just moving compute. Bringing visualization to cloud data is part of that shift.&lt;/p&gt;
&lt;p&gt;Other platforms (Terra, AnVIL) mount cloud storage for interactive apps too. What makes this useful is the &lt;strong&gt;automatic track discovery&lt;/strong&gt;—most solutions require manual file paths.&lt;/p&gt;
&lt;p&gt;The less time you spend moving data around, the more time you spend understanding it.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Robinson JT, et al. (2011). Integrative genomics viewer. Nature Biotechnology 29(1):24-26. &lt;a href=&#34;https://www.nature.com/articles/nbt.1754&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI: 10.1038/nbt.1754&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://igv.org/doc/webapp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IGV Web App Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.seqera.io/platform-cloud/studios/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seqera Studios Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lpantano/custom-studios-examples/tree/master/igv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Implementation Repository&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What Your Running Watch Isn&#39;t Telling You About Cadence</title>
      <link>http://lpantano.github.io/post/2026/2026-01-running-cadence-myth/</link>
      <pubDate>Tue, 13 Jan 2026 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2026/2026-01-running-cadence-myth/</guid>
      <description>&lt;p&gt;I finished another easy run and checked my Garmin. Orange zone. Again.&lt;/p&gt;
&lt;p&gt;My cadence sat around 157 steps per minute. The color warned me something was off. Too slow. Below average. Less experienced.&lt;/p&gt;
&lt;p&gt;But I felt fine. No pain. Sustainable pace with moderate effort. So what was the problem?&lt;/p&gt;
&lt;p&gt;I dug into Garmin&amp;rsquo;s manual to find out. I discovered that, again, I was missing a lot of context to understand this metric.&lt;/p&gt;
&lt;h2 id=&#34;the-colors-are-percentile-rankings&#34;&gt;The Colors Are Percentile Rankings&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s what Garmin&amp;rsquo;s cadence zones actually mean:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Purple (&amp;gt;183 spm):&lt;/strong&gt; Top 5% of all Garmin users&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Blue (174-183 spm):&lt;/strong&gt; 70th-95th percentile&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Green (164-173 spm):&lt;/strong&gt; 30th-69th percentile (&amp;ldquo;average&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Orange (153-163 spm):&lt;/strong&gt; 5th-29th percentile (&amp;ldquo;less experienced or slower&amp;rdquo;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Red (&amp;lt;153 spm):&lt;/strong&gt; Bottom 5%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My orange zone meant I ranked in the 5th-29th percentile compared to other Garmin users.&lt;/p&gt;
&lt;p&gt;Not that my cadence was wrong for my body. Not that I was injured or inefficient. Just that most other Garmin users run with higher cadence.&lt;/p&gt;
&lt;p&gt;These aren&amp;rsquo;t personalized to your body. They&amp;rsquo;re fixed thresholds based on population data. The same thresholds apply whether you&amp;rsquo;re 5&#39;4&amp;quot; or 6&#39;4&amp;quot;, running easy or racing, experienced or brand new.&lt;/p&gt;
&lt;p&gt;The zones compare you to everyone else. They don&amp;rsquo;t tell you what&amp;rsquo;s optimal for you.&lt;/p&gt;
&lt;h2 id=&#34;what-research-actually-shows&#34;&gt;What Research Actually Shows&lt;/h2&gt;
&lt;p&gt;I kept digging. Here&amp;rsquo;s what the research says about cadence:&lt;/p&gt;
&lt;h3 id=&#34;half-of-cadence-is-just-you&#34;&gt;Half of Cadence Is Just You&lt;/h3&gt;
&lt;p&gt;Researchers modeled cadence using leg length, running speed, weight, age, and running experience in 138 youth long-distance runners. These factors explained only 48-55% of the variation between runners (&lt;a href=&#34;https://doi.org/10.1016/j.gaitpost.2022.09.085&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Taylor-Haas et al., 2022, &lt;em&gt;Gait &amp;amp; Posture&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The other ~50%? Unmeasurable individual factors unique to each person—likely including tendon stiffness, muscle fiber length, and muscle group strength patterns that can&amp;rsquo;t be easily measured.&lt;/p&gt;
&lt;p&gt;Elite ultramarathon runners show this clearly. A 2019 study of the top finishers at a 100-km World Championship found cadences ranging from &lt;strong&gt;155 to 203 steps per minute&lt;/strong&gt;—an average of 182 spm (&lt;a href=&#34;https://doi.org/10.1152/japplphysiol.00374.2018&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Burns et al., 2019, &lt;em&gt;Journal of Applied Physiology&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Same performance level. 48-step difference in cadence.&lt;/p&gt;
&lt;h3 id=&#34;height-and-leg-length-matter&#34;&gt;Height and Leg Length Matter&lt;/h3&gt;
&lt;p&gt;The same study found that leg length and running speed together explained approximately 50% of cadence variance (&lt;a href=&#34;https://doi.org/10.1016/j.gaitpost.2022.09.085&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Taylor-Haas et al., 2022&lt;/a&gt;). Shorter leg lengths and faster running speeds were both associated with higher cadence.&lt;/p&gt;
&lt;p&gt;The numbers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Every inch of height = ~3 fewer steps per minute&lt;/li&gt;
&lt;li&gt;A 6-foot runner naturally takes ~18 fewer steps per minute than a 5&#39;6&amp;quot; runner&lt;/li&gt;
&lt;li&gt;Longer legs = lower leg stiffness = naturally lower cadence&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Researchers even created a formula: &lt;code&gt;Cadence = -1.251 × Leg Length (cm) + 3.665 × Speed (m/s) + 254.858&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Calculate your expected cadence:&lt;/strong&gt;&lt;/p&gt;
&lt;div style=&#34;background: #f5f5f5; padding: 20px; border-radius: 8px; margin: 20px 0;&#34;&gt;
  &lt;div style=&#34;margin-bottom: 15px;&#34;&gt;
    &lt;label for=&#34;legLength&#34; style=&#34;display: block; margin-bottom: 5px; font-weight: bold;&#34;&gt;Leg Length (cm):&lt;/label&gt;
    &lt;input type=&#34;number&#34; id=&#34;legLength&#34; placeholder=&#34;e.g., 85&#34; style=&#34;width: 100%; padding: 8px; border: 1px solid #ccc; border-radius: 4px;&#34; /&gt;
    &lt;small style=&#34;color: #666; display: block; margin-top: 3px;&#34;&gt;Measure from hip joint to floor while standing&lt;/small&gt;
  &lt;/div&gt;
  &lt;div style=&#34;margin-bottom: 15px;&#34;&gt;
    &lt;label for=&#34;speed&#34; style=&#34;display: block; margin-bottom: 5px; font-weight: bold;&#34;&gt;Running Speed (m/s):&lt;/label&gt;
    &lt;input type=&#34;number&#34; id=&#34;speed&#34; step=&#34;0.1&#34; placeholder=&#34;e.g., 2.5&#34; style=&#34;width: 100%; padding: 8px; border: 1px solid #ccc; border-radius: 4px;&#34; /&gt;
    &lt;small style=&#34;color: #666; display: block; margin-top: 3px;&#34;&gt;Easy pace: 2.0-2.5 m/s | Tempo: 3.0-3.5 m/s | Race: 3.5+ m/s&lt;/small&gt;
  &lt;/div&gt;
&lt;p&gt;&lt;button onclick=&#34;calculateCadence()&#34; style=&#34;background: #007acc; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; font-weight: bold;&#34;&gt;Calculate&lt;/button&gt;&lt;/p&gt;
  &lt;div id=&#34;result&#34; style=&#34;margin-top: 15px; padding: 15px; background: white; border-radius: 4px; display: none;&#34;&gt;
    &lt;strong&gt;Your Expected Cadence:&lt;/strong&gt; &lt;span id=&#34;cadenceResult&#34; style=&#34;font-size: 1.2em; color: #007acc;&#34;&gt;&lt;/span&gt;
    &lt;p id=&#34;zoneInfo&#34; style=&#34;margin-top: 10px; color: #666;&#34;&gt;&lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;script&gt;
function calculateCadence() {
  const legLength = parseFloat(document.getElementById(&#39;legLength&#39;).value);
  const speed = parseFloat(document.getElementById(&#39;speed&#39;).value);

  if (isNaN(legLength) || isNaN(speed)) {
    alert(&#39;Please enter valid numbers for both fields&#39;);
    return;
  }

  const cadence = -1.251 * legLength + 3.665 * speed + 254.858;
  const roundedCadence = Math.round(cadence);

  document.getElementById(&#39;cadenceResult&#39;).textContent = roundedCadence + &#39; spm&#39;;

  let zoneInfo = &#39;&#39;;
  let zoneColor = &#39;&#39;;
  if (roundedCadence &gt; 183) {
    zoneInfo = &#39;Purple zone (&gt;95th percentile) - &#34;Elite performance&#34;&#39;;
    zoneColor = &#39;#9370DB&#39;;
  } else if (roundedCadence &gt;= 174) {
    zoneInfo = &#39;Blue zone (70-95th percentile) - &#34;Experienced runners&#34;&#39;;
    zoneColor = &#39;#4169E1&#39;;
  } else if (roundedCadence &gt;= 164) {
    zoneInfo = &#39;Green zone (30-69th percentile) - &#34;Average range&#34;&#39;;
    zoneColor = &#39;#32CD32&#39;;
  } else if (roundedCadence &gt;= 153) {
    zoneInfo = &#39;Orange zone (5-29th percentile) - &#34;Below average&#34;&#39;;
    zoneColor = &#39;#FF8C00&#39;;
  } else {
    zoneInfo = &#39;Red zone (&lt;5th percentile) - May warrant investigation&#39;;
    zoneColor = &#39;#DC143C&#39;;
  }

  document.getElementById(&#39;zoneInfo&#39;).innerHTML =
    &#39;&lt;span style=&#34;color: &#39; + zoneColor + &#39;; font-weight: bold;&#34;&gt;Garmin would show: &#39; + zoneInfo + &#39;&lt;/span&gt;&lt;br&gt;&#39; +
    &#39;&lt;em&gt;Remember: This is a population comparison, not a personal assessment.&lt;/em&gt;&#39;;

  document.getElementById(&#39;result&#39;).style.display = &#39;block&#39;;
}
&lt;/script&gt;
&lt;p&gt;Remember, about 50% of cadence variance comes from leg length and running speed. The rest is individual. And this formula comes from one paper and is a guide to help you understand how different factors can affect cadence.&lt;/p&gt;
&lt;h3 id=&#34;speed-changes-your-cadence&#34;&gt;Speed Changes Your Cadence&lt;/h3&gt;
&lt;p&gt;Your cadence at easy pace differs from your cadence at tempo pace. Obviously.&lt;/p&gt;
&lt;p&gt;A 2025 study of 30 experienced recreational runners (running 24+ km/week) examined how cadence changed with running speed. The study confirmed that increasing speed directly increases cadence (&lt;a href=&#34;https://doi.org/10.26603/001c.140544&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Leacox et al., 2025, &lt;em&gt;International Journal of Sports Physical Therapy&lt;/em&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Same runners. Different paces. Different cadences. But there were some exceptions where runners did not increase cadence after a certain point, even as speed increased.&lt;/p&gt;
&lt;p&gt;Garmin&amp;rsquo;s zones don&amp;rsquo;t distinguish between easy runs and hard efforts. An orange zone on an easy day doesn&amp;rsquo;t mean the same thing as orange on a tempo run.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s my association between cadence and speed. The correlation is clear, though there&amp;rsquo;s still variability at the same cadence. I ran in different terrains, different shoes, while sick, and while feeling fine.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;pace_cadence_correlation.png&#34; alt=&#34;Pace and cadence correlation&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;the-180-myth-lives-on&#34;&gt;The 180 Myth Lives On&lt;/h2&gt;
&lt;p&gt;You&amp;rsquo;ve probably heard it: 180 steps per minute is the &amp;ldquo;ideal&amp;rdquo; cadence.&lt;/p&gt;
&lt;p&gt;Garmin&amp;rsquo;s purple zone starts at 183 spm, and mentions it in the explanatory text of the graph as an ideal target.&lt;/p&gt;
&lt;p&gt;I won&amp;rsquo;t dive into the full story of where 180 came from—that would take us down a rabbit hole of observations, elite athletes, and how one number became running gospel. But here&amp;rsquo;s what matters: research shows it doesn&amp;rsquo;t apply to everyone.&lt;/p&gt;
&lt;p&gt;Elite ultramarathoners performing at the same level run with cadences ranging from 155 to 203 steps per minute (&lt;a href=&#34;https://doi.org/10.1152/japplphysiol.00374.2018&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Burns et al., 2019&lt;/a&gt;). That&amp;rsquo;s a 48-step difference. Same performance. Wildly different cadences.&lt;/p&gt;
&lt;p&gt;The 180 rule came from watching elite runners at race pace. Not recreational runners. Not easy pace. Not different body types.&lt;/p&gt;
&lt;p&gt;Yet somehow it became the standard everyone chases.&lt;/p&gt;
&lt;h2 id=&#34;what-this-means-for-you&#34;&gt;What This Means for You&lt;/h2&gt;
&lt;p&gt;Ignore the colors.&lt;/p&gt;
&lt;p&gt;Orange doesn&amp;rsquo;t mean you&amp;rsquo;re doing something wrong. Especially if you&amp;rsquo;re tall, running easy pace, or simply built differently from the average Garmin user.&lt;/p&gt;
&lt;p&gt;The colors rank you against a population. They don&amp;rsquo;t assess your optimal cadence.&lt;/p&gt;
&lt;p&gt;For me, here&amp;rsquo;s a simple decision rule: &lt;strong&gt;If I am in orange or green and feel good, I am fine.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Focus on what actually matters:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Accept that pace changes cadence:&lt;/strong&gt; Your easy runs will have different cadence than your hard efforts. That&amp;rsquo;s normal, not a problem.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Understand the limitations:&lt;/strong&gt; Percentile rankings tell you where you fall in a distribution. They don&amp;rsquo;t tell you what&amp;rsquo;s right for you.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;the-data-literacy-lesson&#34;&gt;The Data Literacy Lesson&lt;/h2&gt;
&lt;p&gt;Your running watch gives you data. Lots of it. But understanding what that data actually measures—versus what you think it measures—makes the difference between useful information and unnecessary anxiety.&lt;/p&gt;
&lt;p&gt;Color zones are percentile rankings. They compare you to other runners. They don&amp;rsquo;t optimize for your body.&lt;/p&gt;
&lt;p&gt;This is how bad data interpretation happens. Not from wrong numbers, but from misunderstanding what the numbers mean.&lt;/p&gt;
&lt;p&gt;An easy solution would be to use better color theme. The problem is they&amp;rsquo;re choosing colors that trigger warning/danger emotions when the messaging isn&amp;rsquo;t about that. That, and adding a better explanation on the info page. It&amp;rsquo;s misleading as it stands.&lt;/p&gt;
&lt;p&gt;Next time you see orange, remember: that color tells you where you rank compared to other Garmin users. It doesn&amp;rsquo;t tell you your cadence is wrong.&lt;/p&gt;
&lt;p&gt;Your body&amp;rsquo;s data matters more than population averages. Trust how you feel. Watch for actual problems (pain, injury, very low cadence). And don&amp;rsquo;t let a percentile comparison convince you that your body is wrong.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;scientific-references&#34;&gt;Scientific References&lt;/h2&gt;
&lt;h3 id=&#34;primary-research-papers&#34;&gt;Primary Research Papers&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Taylor-Haas, J. A., Garcia, M. C., Rauh, M. J., Peel, S., Paterno, M. V., Bazett-Jones, D. M., Ford, K. R., &amp;amp; Long, J. T. (2022).&lt;/strong&gt; Cadence in youth long-distance runners is predicted by leg length and running speed. &lt;em&gt;Gait &amp;amp; Posture&lt;/em&gt;, 98, 266-270. DOI: &lt;a href=&#34;https://doi.org/10.1016/j.gaitpost.2022.09.085&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.1016/j.gaitpost.2022.09.085&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Burns, G. T., Zendler, J. D., &amp;amp; Zernicke, R. F. (2019).&lt;/strong&gt; Step frequency patterns of elite ultramarathon runners during a 100-km road race. &lt;em&gt;Journal of Applied Physiology&lt;/em&gt;, 126(2), 462-468. DOI: &lt;a href=&#34;https://doi.org/10.1152/japplphysiol.00374.2018&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.1152/japplphysiol.00374.2018&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Leacox, A., Fashingbauer, L., Ferguson, T., Zajakowski, A., Baum, B., &amp;amp; Reinking, M. (2025).&lt;/strong&gt; The Effect of Running Speed on Cadence and Running Kinetics. &lt;em&gt;International Journal of Sports Physical Therapy&lt;/em&gt;, 20(7), 957-963. DOI: &lt;a href=&#34;https://doi.org/10.26603/001c.140544&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.26603/001c.140544&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;technical-documentation&#34;&gt;Technical Documentation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Garmin Ltd.&lt;/strong&gt; Forerunner 245/245 Music Owner&amp;rsquo;s Manual - Color Gauges and Running Dynamics Data. Retrieved from &lt;a href=&#34;https://www8.garmin.com/manuals/webhelp/forerunner245/EN-US/GUID-EE9E7F6F-49BE-4452-82E6-B40371D0AEC1.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www8.garmin.com/manuals/webhelp/forerunner245/EN-US/GUID-EE9E7F6F-49BE-4452-82E6-B40371D0AEC1.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Garmin Ltd.&lt;/strong&gt; fēnix 7 Series Owner&amp;rsquo;s Manual - Color Gauges and Running Dynamics Data. Retrieved from &lt;a href=&#34;https://www8.garmin.com/manuals/webhelp/GUID-C001C335-A8EC-4A41-AB0E-BAC434259F92/EN-US/GUID-EE9E7F6F-49BE-4452-82E6-B40371D0AEC1.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www8.garmin.com/manuals/webhelp/GUID-C001C335-A8EC-4A41-AB0E-BAC434259F92/EN-US/GUID-EE9E7F6F-49BE-4452-82E6-B40371D0AEC1.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Single-Cell RNA-Seq Analysis Reports</title>
      <link>http://lpantano.github.io/portfolio/singlecell-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/portfolio/singlecell-reports/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;A collection of code templates and training materials for performing downstream analysis following single-cell RNA preprocessing. This repository provides standardized workflows for researchers working with scRNA-seq data, from quality assessment to differential expression.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View Documentation →&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub Repository →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Quality Assessment&lt;/strong&gt;: Templates for evaluating scRNA and scATAC data quality&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration Analysis&lt;/strong&gt;: Workflows for combining multiple samples with batch effect correction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Differential Expression&lt;/strong&gt;: Multiple approaches including pseudobulk analysis via DESeq2 and MAST methodology&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compositional Analysis&lt;/strong&gt;: Methods for examining cell-type abundance changes across conditions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gene Imputation&lt;/strong&gt;: Techniques using ALRA and MAGIC algorithms to address data sparsity&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipeline Integration&lt;/strong&gt;: Support for nf-core scrnaseq pipeline outputs and standalone Cell Ranger processing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built primarily in R with supporting shell scripts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for single-cell data handling and analysis&lt;/li&gt;
&lt;li&gt;DESeq2 for differential expression analysis&lt;/li&gt;
&lt;li&gt;Harmony for batch effect correction&lt;/li&gt;
&lt;li&gt;nf-core scrnaseq pipeline integration&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for reproducible reports&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates for common scRNA-seq tasks&lt;/li&gt;
&lt;li&gt;Training materials and documentation&lt;/li&gt;
&lt;li&gt;Standardized workflows following best practices&lt;/li&gt;
&lt;li&gt;Integration with popular preprocessing pipelines&lt;/li&gt;
&lt;li&gt;Examples for both scRNA-seq and scATAC-seq data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Templates are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Single-cell RNA-seq analysis requires specialized knowledge and tools. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces the learning curve for new single-cell researchers&lt;/li&gt;
&lt;li&gt;Provides validated workflows following community best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible analysis through standardized templates&lt;/li&gt;
&lt;li&gt;Supports multiple experimental designs and research questions&lt;/li&gt;
&lt;li&gt;Integrates seamlessly with popular preprocessing pipelines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt; or explore the &lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Single-Cell RNA-Seq Analysis Reports</title>
      <link>http://lpantano.github.io/project/singlecell-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/project/singlecell-reports/</guid>
      <description>&lt;p&gt;A collection of code templates and training materials for performing downstream analysis following single-cell RNA preprocessing. This repository provides standardized workflows for researchers working with scRNA-seq data, from quality assessment to differential expression.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View Documentation →&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub Repository →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Quality Assessment&lt;/strong&gt;: Templates for evaluating scRNA and scATAC data quality&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration Analysis&lt;/strong&gt;: Workflows for combining multiple samples with batch effect correction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Differential Expression&lt;/strong&gt;: Multiple approaches including pseudobulk analysis via DESeq2 and MAST methodology&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compositional Analysis&lt;/strong&gt;: Methods for examining cell-type abundance changes across conditions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gene Imputation&lt;/strong&gt;: Techniques using ALRA and MAGIC algorithms to address data sparsity&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipeline Integration&lt;/strong&gt;: Support for nf-core scrnaseq pipeline outputs and standalone Cell Ranger processing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built primarily in R with supporting shell scripts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for single-cell data handling and analysis&lt;/li&gt;
&lt;li&gt;DESeq2 for differential expression analysis&lt;/li&gt;
&lt;li&gt;Harmony for batch effect correction&lt;/li&gt;
&lt;li&gt;nf-core scrnaseq pipeline integration&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for reproducible reports&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates for common scRNA-seq tasks&lt;/li&gt;
&lt;li&gt;Training materials and documentation&lt;/li&gt;
&lt;li&gt;Standardized workflows following best practices&lt;/li&gt;
&lt;li&gt;Integration with popular preprocessing pipelines&lt;/li&gt;
&lt;li&gt;Examples for both scRNA-seq and scATAC-seq data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Templates are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Single-cell RNA-seq analysis requires specialized knowledge and tools. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces the learning curve for new single-cell researchers&lt;/li&gt;
&lt;li&gt;Provides validated workflows following community best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible analysis through standardized templates&lt;/li&gt;
&lt;li&gt;Supports multiple experimental designs and research questions&lt;/li&gt;
&lt;li&gt;Integrates seamlessly with popular preprocessing pipelines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt; or explore the &lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Transcriptomics Analysis Reports</title>
      <link>http://lpantano.github.io/portfolio/spatial-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/portfolio/spatial-reports/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;A template repository providing analysis workflows for spatial single-cell transcriptomics data across multiple experimental platforms and analytical packages. This project offers researchers standardized pipelines for quality control, clustering, and cell-type annotation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View on GitHub →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-Platform Support&lt;/strong&gt;: Templates for COSMX and Visium[HD] spatial transcriptomics platforms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quality Control Pipelines&lt;/strong&gt;: Comprehensive QC assessment workflows for data validation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering Workflows&lt;/strong&gt;: Spatial clustering using Banksy and other established tools&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cell-Type Annotation&lt;/strong&gt;: Integration with spacexr for cell-type identification and differential expression&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reproducible Environment&lt;/strong&gt;: RStudio Projects with renv package management for dependency control&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built entirely in R with integration of leading bioinformatics tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for Visium object handling&lt;/li&gt;
&lt;li&gt;Banksy for spatial clustering analysis&lt;/li&gt;
&lt;li&gt;spacexr for cell-type identification&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for report generation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates&lt;/li&gt;
&lt;li&gt;Downloadable test data for learning and validation&lt;/li&gt;
&lt;li&gt;Dependency installation scripts&lt;/li&gt;
&lt;li&gt;Quick-start documentation for RStudio users&lt;/li&gt;
&lt;li&gt;Standardized workflows across different spatial platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Projects are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Spatial transcriptomics generates complex data requiring specialized analysis approaches. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces setup time for new spatial transcriptomics projects&lt;/li&gt;
&lt;li&gt;Provides validated workflows following best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible research through standardized templates&lt;/li&gt;
&lt;li&gt;Lowers the barrier to entry for spatial data analysis&lt;/li&gt;
&lt;li&gt;Maintains consistency across different experimental platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Transcriptomics Analysis Reports</title>
      <link>http://lpantano.github.io/project/spatial-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/project/spatial-reports/</guid>
      <description>&lt;p&gt;A template repository providing analysis workflows for spatial single-cell transcriptomics data across multiple experimental platforms and analytical packages. This project offers researchers standardized pipelines for quality control, clustering, and cell-type annotation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View on GitHub →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-Platform Support&lt;/strong&gt;: Templates for COSMX and Visium[HD] spatial transcriptomics platforms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quality Control Pipelines&lt;/strong&gt;: Comprehensive QC assessment workflows for data validation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering Workflows&lt;/strong&gt;: Spatial clustering using Banksy and other established tools&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cell-Type Annotation&lt;/strong&gt;: Integration with spacexr for cell-type identification and differential expression&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reproducible Environment&lt;/strong&gt;: RStudio Projects with renv package management for dependency control&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built entirely in R with integration of leading bioinformatics tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for Visium object handling&lt;/li&gt;
&lt;li&gt;Banksy for spatial clustering analysis&lt;/li&gt;
&lt;li&gt;spacexr for cell-type identification&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for report generation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates&lt;/li&gt;
&lt;li&gt;Downloadable test data for learning and validation&lt;/li&gt;
&lt;li&gt;Dependency installation scripts&lt;/li&gt;
&lt;li&gt;Quick-start documentation for RStudio users&lt;/li&gt;
&lt;li&gt;Standardized workflows across different spatial platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Projects are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Spatial transcriptomics generates complex data requiring specialized analysis approaches. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces setup time for new spatial transcriptomics projects&lt;/li&gt;
&lt;li&gt;Provides validated workflows following best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible research through standardized templates&lt;/li&gt;
&lt;li&gt;Lowers the barrier to entry for spatial data analysis&lt;/li&gt;
&lt;li&gt;Maintains consistency across different experimental platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WLD E6 AI for Interviews</title>
      <link>http://lpantano.github.io/tutorials/2026-01-10-wld-e6-ai-for-interviews/</link>
      <pubDate>Sat, 10 Jan 2026 20:24:14 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-10-wld-e6-ai-for-interviews/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/4L1Ypc-KkYc?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Job searching is already exhausting enough without spending hours customizing every application, researching every company, and second-guessing every follow-up email.&lt;/p&gt;
&lt;p&gt;So in this video, we&amp;rsquo;re diving into something really practical: how to use AI as your personal interview prep assistant.&lt;/p&gt;
&lt;p&gt;Lorena interviews Lina about her AI-powered process—from the moment she sees a job posting to after the interview is over. This isn&amp;rsquo;t theoretical advice. These are the actual strategies Lina is using right now during her active job search to:&lt;/p&gt;
&lt;p&gt;✅ Cut application prep time from an hour to 20 minutes
✅ Show up to interviews with strategic questions tailored to each specific interviewer
✅ Research companies and roles more thoroughly than anyone could manually
✅ Process interview feedback and build professional networks systematically&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4L1Ypc-KkYc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WLD E5 Bioinformatics Interviews Decoded</title>
      <link>http://lpantano.github.io/tutorials/2026-01-10-wld-e5-bioinformatics-interviews-decoded/</link>
      <pubDate>Sat, 10 Jan 2026 20:23:43 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-10-wld-e5-bioinformatics-interviews-decoded/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/sjw0bceAHB0?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Hey everyone!&lt;/p&gt;
&lt;p&gt;Lorena and I just finished recording something we WISH we&amp;rsquo;d had when we were starting out: a comprehensive guide to nailing bioinformatics interviews for junior to intermediate roles.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the thing: bioinformatics interviews are uniquely challenging because you&amp;rsquo;re expected to demonstrate expertise across multiple domains—biology, computer science, AND statistics—while also proving you can communicate clearly across all of them. It&amp;rsquo;s a lot. And most people prepare by trying to memorize every tool and algorithm, which honestly isn&amp;rsquo;t what interviewers are looking for.&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sjw0bceAHB0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WLD E4 Amplifying Minorities</title>
      <link>http://lpantano.github.io/tutorials/2026-01-10-wld-e4-amplifying-minorities/</link>
      <pubDate>Sat, 10 Jan 2026 20:22:52 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-10-wld-e4-amplifying-minorities/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/ACNYplq3o_A?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Allyship isn&amp;rsquo;t passive—it requires specific, intentional actions in the moments that matter.&lt;/p&gt;
&lt;p&gt;In this video, Lorena and I break down the practical strategies for amplifying underrepresented voices in professional settings. We&amp;rsquo;re talking about real, in-the-moment tactics you can use:&lt;/p&gt;
&lt;p&gt;✅ How to redirect attention when good ideas get talked over
✅ Strategic ways to prep colleagues before high-stakes meetings
✅ What to say (exactly) when you need to create space for others
✅ How to use your social capital without being performative&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t about grand gestures—it&amp;rsquo;s about the small, consistent actions that actually move the needle. Whether you&amp;rsquo;re in a position of privilege or you&amp;rsquo;re figuring out how to advocate for yourself, these strategies work.&lt;/p&gt;
&lt;p&gt;As always, your support makes this content possible. Thanks for being here.&lt;/p&gt;
&lt;p&gt;Lina &amp;amp; Lorena&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ACNYplq3o_A&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WLD 3 Understanding Your Managers World</title>
      <link>http://lpantano.github.io/tutorials/2026-01-10-wld-3-understanding-your-managers-world/</link>
      <pubDate>Sat, 10 Jan 2026 20:21:45 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-10-wld-3-understanding-your-managers-world/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/TEd7Ri5PNXk?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Most of us learned how to do our jobs, but nobody taught us how to actually work with our managers. And here&amp;rsquo;s the thing: your relationship with your manager can be the difference between feeling stuck and advancing your career – but only if you understand what&amp;rsquo;s really going on in their world.&lt;/p&gt;
&lt;p&gt;This video flips the script on how you think about your manager. Instead of seeing them as someone who just assigns tasks or approves time off, we&amp;rsquo;re showing you how to think of them as your business partner. Because when you understand their pressures, priorities, and what success looks like for them, you can position yourself as someone who makes their life easier – and that&amp;rsquo;s when doors start opening for you.&lt;/p&gt;
&lt;p&gt;Lina &amp;amp; Lorena&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=TEd7Ri5PNXk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WLD 2 Workplace Negativity</title>
      <link>http://lpantano.github.io/tutorials/2026-01-10-wld-2-workplace-negativity/</link>
      <pubDate>Sat, 10 Jan 2026 20:19:25 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-10-wld-2-workplace-negativity/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/ZHP3i7Zvmnc?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;You know that colleague who turns every conversation into a complaint session? Or the team meeting that devolves into gossip and finger-pointing?&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve all been there. And here&amp;rsquo;s what nobody tells you: you don&amp;rsquo;t have to fix it, but you do need a strategy to handle it.&lt;/p&gt;
&lt;p&gt;In this video, we break down:&lt;/p&gt;
&lt;p&gt;Why you&amp;rsquo;re not responsible for being everyone&amp;rsquo;s emotional dumping ground&lt;/p&gt;
&lt;p&gt;The 3-step framework for handling chronic complainers (without being dismissive)&lt;/p&gt;
&lt;p&gt;How to redirect gossip and drama toward actual solutions&lt;/p&gt;
&lt;p&gt;The language that transforms negative energy in real-time&lt;/p&gt;
&lt;p&gt;How to set boundaries that protect your own mental space&lt;/p&gt;
&lt;p&gt;The reality? Negativity spreads like wildfire in workplaces. But the good news is that positivity is just as contagious—when you know how to lead it.&lt;/p&gt;
&lt;p&gt;This isn&amp;rsquo;t about toxic positivity or pretending problems don&amp;rsquo;t exist. It&amp;rsquo;s about separating legitimate work issues from drama, and knowing exactly what to say when someone starts spiraling.&lt;/p&gt;
&lt;p&gt;—Lina &amp;amp; Lorena&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ZHP3i7Zvmnc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>WLD 1   Weekly Log</title>
      <link>http://lpantano.github.io/tutorials/2026-01-10-wld-1-weekly-log/</link>
      <pubDate>Sat, 10 Jan 2026 20:17:57 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2026-01-10-wld-1-weekly-log/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/98FNU1ul_Iw?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;Welcome to our first episode! Today we&amp;rsquo;re diving into something that sounds deceptively simple but is genuinely career-changing: keeping a weekly log of your wins and quantifying your achievements. This isn&amp;rsquo;t just for performance review season (though it&amp;rsquo;s a lifesaver then) – it&amp;rsquo;s your secret weapon for fighting imposter syndrome, building an impressive resume, and having concrete evidence ready when it&amp;rsquo;s time to negotiate that raise. Five minutes every Friday. That&amp;rsquo;s all it takes.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve created a one-page Quick Reference Guide (download below!) that you can print and keep at your desk. It covers why this matters, what to log, how to quantify your impact with real before/after examples, and practical setup tips. No more scrambling to remember what you accomplished six months ago. No more underselling yourself because you forgot the numbers. Just a simple habit that pays dividends for years to come.&lt;/p&gt;
&lt;p&gt;Watch the video, grab your guide, and start your first weekly win log this Friday. Seriously – set that 5-minute calendar reminder right now. Your future self (especially the one negotiating salary or updating their resume) will thank you. Drop a comment and let us know what system you&amp;rsquo;re using – Notion? Google Doc? Notes app? We&amp;rsquo;d love to hear what works for you!&lt;/p&gt;
&lt;p&gt;Happy logging! 📊 – Lorena &amp;amp; Lina&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=98FNU1ul_Iw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Beyond the Pipeline: Advancing Diversity in Challenging Times</title>
      <link>http://lpantano.github.io/post/2025/2025-05-diversity-panel/</link>
      <pubDate>Tue, 20 May 2025 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2025/2025-05-diversity-panel/</guid>
      <description>&lt;p&gt;Last Friday, I had the chance to join a panel discussion on advancing diversity in challenging times. I was lucky to be joined by two brilliant next-gen scientists, &lt;a href=&#34;https://www.linkedin.com/in/francinecamacho/?lipi=urn%3Ali%3Apage%3Ad_flagship3_detail_base%3BBqo6ti1rRYmn%2BfbiVPaiWA%3D%3D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Francince Camacho&lt;/a&gt; and &lt;a href=&#34;https://www.linkedin.com/in/saba-nafees/?lipi=urn%3Ali%3Apage%3Ad_flagship3_detail_base%3BBqo6ti1rRYmn%2BfbiVPaiWA%3D%3D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Saba Nafees&lt;/a&gt;. Follow them—they’re going to be incredible leaders and influencers in our field and beyond.&lt;/p&gt;
&lt;p&gt;The session was private, intentionally, to create a safe space where we could speak openly. That setup mattered. I’ve been advocating for equal opportunities since I started in science 15 years ago, and this discussion hit close to home. It’s a topic I never get tired of thinking about—because each time, I learn something new.&lt;/p&gt;
&lt;p&gt;Before diving into my takeaways, I want to give a &lt;strong&gt;big shout-out to the Nextflow Summit&lt;/strong&gt;. It was one of the most welcoming events I’ve attended: committed to diversity, showcasing a wide range of voices (check out the speakers and keynotes!), and even organizing a hackathon with enough women to make me feel right at home—which, believe me, is rare in tech spaces. It’s such a relief to be in a room and not feel like you’re the only one representing a group.&lt;/p&gt;
&lt;p&gt;Here’s something I want to be clear about: &lt;strong&gt;we don’t need any kind of special treatment to be in this field&lt;/strong&gt;. Bioinformatics doesn’t come with a gender requirement. What we do need is equal treatment.&lt;/p&gt;
&lt;p&gt;The reasons some of us don’t come back to conferences or workplaces? It&amp;rsquo;s not complicated. &lt;strong&gt;Sexual comments&lt;/strong&gt; (which somehow still happen and are still not funny), &lt;strong&gt;being talked over,&lt;/strong&gt; or hearing one of &lt;strong&gt;our ideas repeated back to us&lt;/strong&gt;—by someone else claiming it as their own. Yep, that still happens.&lt;/p&gt;
&lt;p&gt;We no longer need to prove that diversity makes science better—there&amp;rsquo;s already plenty of research on that. Honestly, we all just want a fair shot. &lt;strong&gt;Equal opportunities to work hard and be recognized&lt;/strong&gt;. If you don’t see the inequality, that’s okay, but science has shown it’s real.
Yes, things have improved. But &lt;strong&gt;leadership roles are still very male-dominated&lt;/strong&gt; &lt;a href=&#34;https://leanin.org/women-in-the-workplace&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;see LeanIn.org for stats&lt;/a&gt;. I won’t go into a long rant—but if you think there’s a reason beyond unconscious bias or unequal opportunities to explain this gap, I dare you: send me a scientifically backed explanation. I’m all ears.&lt;/p&gt;
&lt;p&gt;At this point, you might be feeling one of a few things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You’re a man—maybe even a white man—and you’ve had a hard time too, maybe even felt discriminated against. First, I’m sorry. That sucks, and I know what that feels like. But that doesn’t mean your experience is representative of the average. On average, women still face more barriers. Let’s work together so that no one gets left out or mistreated.&lt;/li&gt;
&lt;li&gt;You’re a man who’s never seen any of this happen. Great—happy for you! Now go ask your female coworkers what they’ve experienced.&lt;/li&gt;
&lt;li&gt;This all makes sense to you.&lt;/li&gt;
&lt;li&gt;Or&amp;hellip; you think this is all BS and everything’s fine. If that’s the case, you’ve probably stopped reading by now.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So what can we do?&lt;/p&gt;
&lt;p&gt;There’s one simple, powerful thing every ally can do—and if even 1 in 5 people with privilege did it, things would improve fast:&lt;/p&gt;
&lt;p&gt;At work, be a good colleague to a woman. Then &lt;strong&gt;ask her, “How can I support your career?” And then—try to do it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;That’s it. You’d be surprised how little it takes to make a big difference. But I’ll be honest—it might not be “comfortable.” You might have to stand up in front of other colleagues. And then two things will happen:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Some coworkers will join you.&lt;/li&gt;
&lt;li&gt;Others might see you as that person—an annoying advocate—and you may lose a bit of their privileged support.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is where it gets real. You’ll have to choose: &lt;strong&gt;what kind of career, and what kind of world, do you want to help build?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;But here’s the thing: the more people who speak up, the less risky it becomes for any one person. Quiet support and private “likes” aren’t enough anymore. We need action. Especially from men. Now more than ever.&lt;/p&gt;
&lt;p&gt;No one has ever asked me how they could help support my career. Not once.&lt;/p&gt;
&lt;p&gt;So if you’re one of the people deciding to do something—thank you. Really. Welcome to the community. Let’s keep moving forward, together.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unified, community-developed analysis guidelines and templates for multi-omics data interpretability</title>
      <link>http://lpantano.github.io/talk/nextflow2025/</link>
      <pubDate>Thu, 15 May 2025 14:15:00 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/nextflow2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Lorena Pantano: Unified, community-developed analysis guidelines and templates for multi-omics data interpretability</title>
      <link>http://lpantano.github.io/talk/abrf2025/</link>
      <pubDate>Tue, 25 Mar 2025 14:15:00 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/abrf2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Showcase: My Quick Dive into Pipeline Automation with Seqera AI</title>
      <link>http://lpantano.github.io/post/2024/nextflow_seqera_ai_in_30min/</link>
      <pubDate>Thu, 21 Nov 2024 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2024/nextflow_seqera_ai_in_30min/</guid>
      <description>&lt;p&gt;Today, I encountered a familiar dilemma that seems to pop up whenever a simple task comes my way: should I stick to the tried-and-true methods, or should I embrace automation? This time, it was about subsampling raw sequencing data. In my group, we&amp;rsquo;ve been doing this for ages: copy-pasting an SBATCH script, loading the necessary modules, tweaking the code, submitting it to the cluster, and then closely monitoring it. It usually gets the job done.&lt;/p&gt;
&lt;p&gt;But, we&amp;rsquo;re living in exciting times! With tools like &lt;a href=&#34;https://www.nextflow.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nextflow&lt;/a&gt;, &lt;a href=&#34;https://seqera.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seqera&lt;/a&gt;, and &lt;a href=&#34;https://seqera.io/ask-ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seqera AI&lt;/a&gt;, I decided to take a leap and harness the power of Seqera AI to create a small Nextflow pipeline for processing fastq files and generating subsampled outputs. Within just 30 minutes, I managed to build a &lt;a href=&#34;https://github.com/bcbio/nextflow-subsample/tree/main&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pipeline&lt;/a&gt; using the seqtk nfcore/module, complete with test data, and config files that enabled Docker compatibility and execution within our Seqera Workspace. Okay, full disclosure, someone else on the team actually ran the pipeline, what makes this even a better example of accesibility.&lt;/p&gt;
&lt;p&gt;Of course, AI didn&amp;rsquo;t do all the work for me; it simply kick-started the process. As someone who knows a thing or two about development, I was able to troubleshoot and refine what the AI initially provided. The pipeline did run, but we hit a snag with jobs failing due to memory constraints. It turned out our output files were pretty hefty, so I delved into the tool&amp;rsquo;s parameters and quickly adjusted the necessary config settings. Problem solved!&lt;/p&gt;
&lt;p&gt;This experience is a testament to how we can speed up analyses without sacrificing reproducibility or accessibility. And thanks to Seqera, pinpointing the memory issue was a breeze. I genuinely believe adopting such tools will lower the barriers to creating small or infrequent projects and ultimately improve our research. So, why not give your own small pipeline a shot?&lt;/p&gt;
&lt;p&gt;And yes, this post got a little help from Harvard Open AI GPT-4 to bring it to you.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Training Progress Dashboard</title>
      <link>http://lpantano.github.io/portfolio/training-dashboard/</link>
      <pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/portfolio/training-dashboard/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;An interactive dashboard built with React.js that visualizes personal training data from Apple Health and Garmin Connect apps. This project demonstrates data visualization best practices and the importance of personal data ownership.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://run-training-activities.netlify.app&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View Live Dashboard →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-source Data Integration&lt;/strong&gt;: Combines data from Apple Health and Garmin Connect&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interactive Visualizations&lt;/strong&gt;: Track adaptations in speed, distance, time, and heart rate over time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Responsive Design&lt;/strong&gt;: Built with React.js for a smooth user experience&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Ownership Focus&lt;/strong&gt;: Demonstrates how individuals can take control of their health data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-approach&#34;&gt;Technical Approach&lt;/h2&gt;
&lt;p&gt;This dashboard emphasizes the importance of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Personal data ownership and management&lt;/li&gt;
&lt;li&gt;Standardized data export formats&lt;/li&gt;
&lt;li&gt;Independent data analysis capabilities&lt;/li&gt;
&lt;li&gt;User empowerment over corporate data silos&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-shows&#34;&gt;What It Shows&lt;/h2&gt;
&lt;p&gt;The dashboard tracks my personal training progress, revealing patterns in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Speed improvements over time&lt;/li&gt;
&lt;li&gt;Distance progression&lt;/li&gt;
&lt;li&gt;Heart rate adaptation&lt;/li&gt;
&lt;li&gt;Training consistency&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Future enhancements will correlate this data with broader health insights to provide a more comprehensive view of fitness and well-being.&lt;/p&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Too often, our personal health data is locked in proprietary apps or leveraged by large corporations. This project advocates for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apps offering data export in standardized formats&lt;/li&gt;
&lt;li&gt;Individual control over personal data&lt;/li&gt;
&lt;li&gt;Informed decision-making through accessible analytics&lt;/li&gt;
&lt;li&gt;Independence from vendor lock-in&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to discuss similar visualization projects, feel free to reach out.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Training Progress Dashboard</title>
      <link>http://lpantano.github.io/project/training/</link>
      <pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/project/training/</guid>
      <description>&lt;p&gt;An interactive dashboard built with React.js that visualizes personal training data from Apple Health and Garmin Connect apps. This project demonstrates data visualization best practices and the importance of personal data ownership.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://run-training-activities.netlify.app&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View Live Dashboard →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-source Data Integration&lt;/strong&gt;: Combines data from Apple Health and Garmin Connect&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interactive Visualizations&lt;/strong&gt;: Track adaptations in speed, distance, time, and heart rate over time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Responsive Design&lt;/strong&gt;: Built with React.js for a smooth user experience&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Ownership Focus&lt;/strong&gt;: Demonstrates how individuals can take control of their health data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-approach&#34;&gt;Technical Approach&lt;/h2&gt;
&lt;p&gt;This dashboard emphasizes the importance of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Personal data ownership and management&lt;/li&gt;
&lt;li&gt;Standardized data export formats&lt;/li&gt;
&lt;li&gt;Independent data analysis capabilities&lt;/li&gt;
&lt;li&gt;User empowerment over corporate data silos&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-shows&#34;&gt;What It Shows&lt;/h2&gt;
&lt;p&gt;The dashboard tracks my personal training progress, revealing patterns in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Speed improvements over time&lt;/li&gt;
&lt;li&gt;Distance progression&lt;/li&gt;
&lt;li&gt;Heart rate adaptation&lt;/li&gt;
&lt;li&gt;Training consistency&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Future enhancements will correlate this data with broader health insights to provide a more comprehensive view of fitness and well-being.&lt;/p&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Too often, our personal health data is locked in proprietary apps or leveraged by large corporations. This project advocates for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apps offering data export in standardized formats&lt;/li&gt;
&lt;li&gt;Individual control over personal data&lt;/li&gt;
&lt;li&gt;Informed decision-making through accessible analytics&lt;/li&gt;
&lt;li&gt;Independence from vendor lock-in&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to discuss similar visualization projects, feel free to reach out.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Perspective: Note directed to leadership in Biology, Translational, Chemistry and Technology.</title>
      <link>http://lpantano.github.io/post/2024/2024-08-perspective1/</link>
      <pubDate>Thu, 15 Aug 2024 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2024/2024-08-perspective1/</guid>
      <description>&lt;p&gt;Do you work with Computational Biology/Bioinformatics scientists (CBS)? Do you value their work and relationship? Answer these questions and I will tell you:
Have you ever generated data without talking to a CBS and then had a meeting to tell them what you need and what to do?
Have you ever met with a CBS to tell them the figure you want or the analysis you wish for without discussing the scientific hypothesis?
Have you ever made a timeline or assured delivery of a project that involves analysis of a CBS team without discussing it deeply with them?&lt;/p&gt;
&lt;p&gt;If you answer YES to any of that, then you are not appreciating Computational Biology scientists (I know it isn&amp;rsquo;t what you mean) and you are making your life more difficult. Not only that, but your projects are NOT efficiently executed, and there will be a lot of frustration and delays because of not talking to us first.&lt;/p&gt;
&lt;p&gt;But it is EASY to change. Next time you think you need to generate any high-throughput data, before even planning the experiment, start meeting with the CBS team. Explain your scientific hypothesis or question, and ask us: Do you know any technology to generate data that will support or not this hypothesis? What are the key aspects we need to think about for the experimental design? What resources do you need? What limitations do you see? Computational biologists are not a Microsoft Office Suite for other fields. We understand the technologies that generate the data we analyze. For instance, there is nothing simple about RNAseq. There are more than 60 steps from your cells to raw data, and there are more than 50 computational methods applied to the data to get you the best gene expression estimation. Protocols get cheaper, shorter and automated, but they are still COMPLEX. The analysis gets faster and cheaper, but they are still COMPLEX. Not because you don&amp;rsquo;t see it, it is not there. There is no perfect technology; all of them are approximations, and only the experts who have spent years with them will know how to go from estimation to insights.&lt;/p&gt;
&lt;p&gt;I hope this post saves one project. Just try next time to initiate the effort meeting with the CBS the moment you have the IDEA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BaWIB X BWCB joint meetup! Leveraging Mentorship Through Career Hurdles</title>
      <link>http://lpantano.github.io/talk/panel2024wib/</link>
      <pubDate>Wed, 12 Jun 2024 18:00:00 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/panel2024wib/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Lorena Pantano: Transitioning through the nf-core era at the Harvard Chan Bioinformatics Core</title>
      <link>http://lpantano.github.io/talk/nextflow2024/</link>
      <pubDate>Thu, 23 May 2024 14:15:00 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/nextflow2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>My Learning Experience with Computational Infrastructure in Biotech/Industry</title>
      <link>http://lpantano.github.io/post/2024/2024-02-learning-infrastructure/</link>
      <pubDate>Wed, 28 Feb 2024 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2024/2024-02-learning-infrastructure/</guid>
      <description>&lt;p&gt;And here we go again, after 5 years working in early-stage companies, I decided to share what I learned about building an infrastructure that works for the needs of a small company. Note, that there won&amp;rsquo;t be a unique solution to this, and depending on the data input throughput the strategy will change. A good introduction to DataOmics and why this is important can be found at &lt;a href=&#34;https://www.youtube.com/@hammerspace_globaldata&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hammerspace&lt;/a&gt; in an interview with &lt;a href=&#34;https://youtu.be/GpTY019G2DM?si=YDahYJ9H_Lrfy2qH&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Eleanor Howe&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before I start, many other great experts have already talked about this, I learned from them and applied much of what they have said: &lt;a href=&#34;https://www.tumblr.com/michelebusby/643211974587629568/so-you-want-to-start-a-biotech-a-bioinformatics?source=share&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Michele Busby&lt;/a&gt;, and recently from &lt;a href=&#34;https://cep.dev/posts/every-infrastructure-decision-i-endorse-or-regret-after-4-years-running-infrastructure-at-a-startup/?utm_source=tldrnewsletter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jack Lindamood&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now some context, because context matters. I built everything from scratch at NextRNA. This company focused on targeting lncRNA-protein interactions with small molecules to expand the therapy landscape in oncology and neurodegeneration. The data we use is mainly RNAseq, since we are focusing on detecting lncRNA drivers. We have to internalize raw data from big studies like &lt;a href=&#34;https://www.cancer.gov/ccg/research/genome-sequencing/tcga&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TCGA&lt;/a&gt; and similar, to re-analyze it with our pipeline and annotation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://aws.amazon.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AWS cloud services&lt;/a&gt; are what is working for us, and it helps us to be stable.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Network&lt;/strong&gt;: we have two VPCs, with two subnets (private and public). We only use the private subnet and we connect to them through the VPN Client services and with the VPN tunnels to our office. All machines have specific group security configurations to allow only the machine-to-machine communication we know will happen. This can be painful, but it will keep you aware of what is accessible. One VPC is dedicated to shared servers ( I will talk later about this), and another, to machines that will be created through the Batch service, you can call it our HPC space.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage&lt;/strong&gt;: we use mainly S3, we have different buckets depending on data usage policies. We store controlled data that needs to follow specific data usage agreements with NIH. We have permanent processed data and raw data with different storage classes to make it more cost-effective. We have an EFS that is mounted on our shared servers, so every temporary data that we need meanwhile we run downstream data analyses can be accessed from different applications. Some of this data is not temporary but is small and need fast access by Web-Apps, so we keep it here instead of S3.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shared Servers&lt;/strong&gt;: we decided to go with the now-name Posit Bundle: workbench, connect and package manager. This together with our shared file system has made my team collaboration very efficient. About the software, we use all the same R version, with the same R packages. This ensures reproducibility. We decide as a team, the time to update to the next R version and what are the migration steps needed for this. This allows us to publish visualization tools very easily as well, and it has fostered the relationship with the other groups in the company. Nothing gives me more joy than seeing my team talking every day with colleagues from other groups.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipelines&lt;/strong&gt;: The biggest contribution to our better efficiency has been using Seqera platform together with NextFlow pipelines. I will always go with this, it makes it so easy to know what is going on, help debug, relaunch pipelines&amp;hellip; And there are features we are not using yet that will make many other processes easier, like datasets ready to be analyzed at any point, visualizing reports, spin-off on-demand machines&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: this is not new, but I want to share how we use it. We decided on some naming conventions for repositories, have templates repositories, and have documentation in the repository. Have a company internal package that collects all the common code that is used now and then, so we make sure that repetitive analyses of data are the same, and anybody can work on them. As well we have our figure theme so we are consistent when we create reports. We use it a lot for BD material creation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, even if it is not part of the computing infrastructure, I would say managing projects efficiently is important. We tried different things, but what worked the best was &lt;a href=&#34;https://trello.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Trello&lt;/a&gt;. We decided on a protocol on what a card would mean, how to annotate the card, how to see the workload of the team only by looking at the Trello board&amp;hellip;and it worked like magic. We have a weekly meeting to align on the short-term goals and long-term goals and plan accordingly.&lt;/p&gt;
&lt;p&gt;Other solutions I know they will be good but I couldn&amp;rsquo;t explore more because of time constraints and budget limitations. For instance, &lt;a href=&#34;https://codeocean.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Code Ocean&lt;/a&gt;. I know about &lt;a href=&#34;https://www.deeporigin.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Deep Origin&lt;/a&gt;, it would be more like an advanced software as a service but it could be part of the overall infrastructure to accelerate the time between data and decision. Similar companies, like &lt;a href=&#34;https://bigomics.ch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BigOmics&lt;/a&gt; helps to analyze data quickly without thinking on the backend. &lt;a href=&#34;https://biobox.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BioBox&lt;/a&gt; is working in new products as well, this one focused on graph data representation.&lt;/p&gt;
&lt;p&gt;More focused on data, I would evaluate &lt;a href=&#34;https://tiledb.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TileDB&lt;/a&gt; and &lt;a href=&#34;https://www.databricks.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Databricks&lt;/a&gt; when the time is right and the amount of data and integration are a limitation to your process. If you need more help with this, I recently met &lt;a href=&#34;https://scalingbiotech.substack.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jesse Johnson&lt;/a&gt;, he is an expert in the data space working with Biotechs.&lt;/p&gt;
&lt;p&gt;This is a summary, but I hope it is enough to give a broad idea. Happy to talk with anybody who wants to know more. This strategy was highly influenced by &lt;a href=&#34;https://www.linkedin.com/in/judith-flo-gaya-8999394/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Judit Flo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3D-printer WALL-E toilet paper holder</title>
      <link>http://lpantano.github.io/post/2023/walle/</link>
      <pubDate>Sat, 09 Dec 2023 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2023/walle/</guid>
      <description>&lt;p&gt;It was that time that after 6 months of having the TP holder broken, we decided to make a cute update. It took a couple of months to finish it. Thanks to &lt;a href=&#34;https://www.thingiverse.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thingverse&lt;/a&gt; for the &lt;a href=&#34;https://www.thingiverse.com/thing:3709814&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;model&lt;/a&gt; with some tweaks.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2023/walle/IMG_3353_hu_a5e4420abf21d8c1.webp 400w,
               /post/2023/walle/IMG_3353_hu_39ae0226a9476090.webp 760w,
               /post/2023/walle/IMG_3353_hu_a4185cc5d22dcfe1.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2023/walle/IMG_3353_hu_a5e4420abf21d8c1.webp&#34;
               width=&#34;283&#34;
               height=&#34;378&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2023/walle/IMG_4178_hu_129591ee036add63.webp 400w,
               /post/2023/walle/IMG_4178_hu_f15eb403dc00b4c9.webp 760w,
               /post/2023/walle/IMG_4178_hu_3b6f3044e33f8521.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2023/walle/IMG_4178_hu_129591ee036add63.webp&#34;
               width=&#34;283&#34;
               height=&#34;378&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2023/walle/IMG_4179_hu_8a4910625f18f70b.webp 400w,
               /post/2023/walle/IMG_4179_hu_6dbfa487866d725b.webp 760w,
               /post/2023/walle/IMG_4179_hu_3859564aaf41c6eb.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2023/walle/IMG_4179_hu_8a4910625f18f70b.webp&#34;
               width=&#34;283&#34;
               height=&#34;420&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2023/walle/IMG_4193_hu_7719dcd74f22fc51.webp 400w,
               /post/2023/walle/IMG_4193_hu_96e81f4418add0b0.webp 760w,
               /post/2023/walle/IMG_4193_hu_bba55a48ec6099db.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2023/walle/IMG_4193_hu_7719dcd74f22fc51.webp&#34;
               width=&#34;283&#34;
               height=&#34;257&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /post/2023/walle/IMG_4195_hu_5432e57cb70ddb03.webp 400w,
               /post/2023/walle/IMG_4195_hu_d090ddedfc902e77.webp 760w,
               /post/2023/walle/IMG_4195_hu_dd8656da2c57d012.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2023/walle/IMG_4195_hu_5432e57cb70ddb03.webp&#34;
               width=&#34;283&#34;
               height=&#34;378&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My story with cancer - Jimmy fund walk Oct 1st</title>
      <link>http://lpantano.github.io/post/2023/2023-06-01-raising-for-cancer-research/</link>
      <pubDate>Thu, 01 Jun 2023 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2023/2023-06-01-raising-for-cancer-research/</guid>
      <description>&lt;p&gt;Last year my mom got cancer, multiple myeloma. I didn&amp;rsquo;t know anything about this cancer, and I discovered how horrible it is, even if treatment is available, people get misdiagnosed all the time, and there is no cure. I am doing the marathon this year with the Jimmy fund walk event. NextRNA, the company I work for, joined as a team, and it gave me the opportunity to do something and share my story to bring awareness.&lt;/p&gt;
&lt;p&gt;Please, if you can, add a few $$ to my fund-raising page: &lt;a href=&#34;http://danafarber.jimmyfund.org/goto/lopantano&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://danafarber.jimmyfund.org/goto/lopantano&lt;/a&gt;, and/or share the link with friends. Any amount will impact people like my mom.&lt;/p&gt;
&lt;h2 id=&#34;june-18-6-miles&#34;&gt;June 18, 6 miles&lt;/h2&gt;
&lt;p&gt;Chapter 01: September 2022, my mom started with some back pain and started to lose mobility. She stopped doing her normal activity.&lt;/p&gt;
&lt;h2 id=&#34;june-24-75-miles&#34;&gt;June 24, 7.5 miles&lt;/h2&gt;
&lt;p&gt;Chapter 02: One month later, doctors only gave her pain medication, all kinds, nothing was working, and she was not able to walk or sit. The health system denied her any kind of imaging to evaluate further.&lt;/p&gt;
&lt;h2 id=&#34;july-1-9-miles&#34;&gt;July 1, 9 miles&lt;/h2&gt;
&lt;p&gt;Chapter 03: November 2022, my mom was getting worse, not able to move at all, and starting to lose short-term memory and not able to maintain a normal conversation. After a lot of push from my dad, they got a referral from primary care to get an MRI in a private clinic. We needed to wait for 1 more week now.&lt;/p&gt;
&lt;h2 id=&#34;july-8-105-miles&#34;&gt;July 8, 10.5 miles&lt;/h2&gt;
&lt;p&gt;Chapter 04: In December 2022, my mom got accepted into the hospital after having results from the MRI that showed some kind of cancer inside the bones. She had broken discs and ribs. In one day we knew it was MM, protein M levels were incredibly high. At this point, she was spending all the time in bed. She was disoriented. I bought a ticket to Spain right away.&lt;/p&gt;
&lt;h2 id=&#34;july-15-12-miles&#34;&gt;July 15, 12 miles&lt;/h2&gt;
&lt;p&gt;Chapter 05: Still in December 2022, I arrived there to see my mom in bed and told me not to touch her too hard because it hurts&amp;hellip;my heart broke. It was late, so I went to bed. The next morning I saw my mom standing up, so weak. That weak was all about finding new ways to make her more comfortable. She couldn&amp;rsquo;t sit for more than 20 minutes, she could barely eat. It was week two of chemotherapy and nausea was a strong side effect.&lt;/p&gt;
&lt;h2 id=&#34;july-22-134-miles&#34;&gt;July 22, 13.4 miles&lt;/h2&gt;
&lt;p&gt;Chapter 06: Still in December 2022, we were figuring out everything still. In her third week of chemotherapy, she got a strong reaction to the skin. She was red all over the belly. It was scary, and her PCP didn&amp;rsquo;t want to give her anything because she didn&amp;rsquo;t know what could happen with her treatment. The PCP told us to go to her oncologist. But, and big BUT, the system is not ready to contact your oncologist. Your option is to go to ER and spend 6 hours until somebody decides if they contact the oncologist. I had to go with my dad to the hospital and intercept her oncologist in the corridor. But we didn&amp;rsquo;t find him, so we asked a nurse who had some compassion for us and call the oncologist. He told us to come the next day and ask for an appointment during the day. We had to wait 3 hours the next day, with my mom in a wheelchair in pain and taking morphine every 2 hours. It was a reaction to some antibiotic. It took 2 weeks to go away.&lt;/p&gt;
&lt;h2 id=&#34;july-30-13-miles&#34;&gt;July 30, 13 miles&lt;/h2&gt;
&lt;p&gt;Chapter 07: December 25th, After this, we got to just live one day at a time. Christmas came, we celebrate as we could. We had dinner at 7 pm and my mom was in bed at 8 pm as any other day. It was so sad seeing her eat that little. My mom enjoyed cooking and eating, but this year was not like that.&lt;/p&gt;
&lt;h2 id=&#34;august-12-9-miles-back-from-vacation&#34;&gt;August 12, 9 miles (back from vacation)&lt;/h2&gt;
&lt;p&gt;Chapter 08: December 31st, Nothing else happened that last week of the year. New Year&amp;rsquo;s Eve came and we did the same as a normal day. I cooked some traditional empanadas and we were done by 8 pm. She barely could stay sitting for more than 20 minutes.  She still needed help getting ready for bed. Amazingly, she could still go upstairs by herself though.&lt;/p&gt;
&lt;h2 id=&#34;august-19-12-miles-back-on-training-mode&#34;&gt;August 19, 12 miles (back on training mode)&lt;/h2&gt;
&lt;p&gt;Chapter 09: January 2023, last week of treatment. The first week of January she started to be able to change clothes by herself. That was nice to see. Gain some independence. We decided to walk for 10 minutes one day, and we repeated the next day. That helped her. It was time for me to come back to Boston. After all this month, at least my mom was moving a little bit more, and treatment seemed to be working. Protein M reduced by 50%.&lt;/p&gt;
&lt;h2 id=&#34;september-2-16-miles-hike-in-ct&#34;&gt;September 2, 16 miles (hike in CT)&lt;/h2&gt;
&lt;p&gt;Chapter 10:  February 2023, the second cycle went without any surprise. Some skin reactions, but nothing compared to everything she went through in the past months. I tried to call every day, but it was difficult with work and time difference. Still, I could see she could move more. She kept walking 10min a day.&lt;/p&gt;
&lt;h2 id=&#34;september-9-18-miles&#34;&gt;September 9, 18 miles&lt;/h2&gt;
&lt;p&gt;Chapter 11: May to August 2023. She went through 4 more cycles, a total of 6 at this point. Numbers were going down every time. Although she improved, the pain is still there. Two weeks before I went to visit this past summer, she got a stomach virus that left her in bed again. No strength. They spent 5h in the emergency room to know it was nothing related to the cancer. Still, scary.&lt;/p&gt;
&lt;h2 id=&#34;september-16-10-miles-15minmiles-that-is-fast&#34;&gt;September 16, 10 miles (15min/miles, that is fast&amp;hellip;)&lt;/h2&gt;
&lt;p&gt;Chapter 12: August 2023. When I got there she was better from the stomach and energy, but she got a respiratory virus. This was really scary, because she got fever and couldn&amp;rsquo;t breathe. Again to the ER, 5h more. They said nothing more than a virus. We went home, and in the middle of the night, she woke up coughing like crazy to the point of not being able to breathe. She was very scared, we all were. We spent 1h in the bathroom with hot water, and that helped. I don&amp;rsquo;t know how I could remember that. She told me stories that she would do that whenever I got sick when I was little. The night passed and another day went on. On top of that, the antibiotic she was taking was causing depression. I had to leave to Boston, she was better physically, but mentally really bad.&lt;/p&gt;
&lt;h2 id=&#34;september-23-12-miles-last-training-day&#34;&gt;September 23, 12 miles (last training day)&lt;/h2&gt;
&lt;p&gt;Chapter 13: Current time. It took 4 weeks for my mom to recover from those infections. Now she is better, almost like she was before last month&amp;rsquo;s episode. Treatment continues to work, but the pain is still there, and maybe forever there. I cannot stop thinking that with a diagnosis 1 month earlier, she could have a much better quality of life. I cannot stop thinking that the treatment is much better but there is no cure. That is why I am walking, and I appreciate everybody who read this and/or donated money in my name ( even now with all this crisis happening). Ultimately, this is why I am a researcher, because there is still a lot of work to do to give people suffering a healthy condition a second chance.&lt;/p&gt;
&lt;h2 id=&#34;october-1-262-miles&#34;&gt;October 1, 26.2 miles&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Women in Life Sciences: How do we Close the Gender Gap in Leadership?</title>
      <link>http://lpantano.github.io/talk/biotalent2021/</link>
      <pubDate>Sat, 18 Sep 2021 00:00:00 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/biotalent2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inside a Bioinformatics Startup – with NextRNA Therapeutics</title>
      <link>http://lpantano.github.io/talk/nextflow2021/</link>
      <pubDate>Wed, 15 Sep 2021 00:00:00 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/nextflow2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>My transition to biotech</title>
      <link>http://lpantano.github.io/post/2019/2019-10-03-move-to-egenesis/</link>
      <pubDate>Thu, 03 Oct 2019 17:42:40 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2019/2019-10-03-move-to-egenesis/</guid>
      <description>&lt;p&gt;If you came here it is because the twitter wasn’t enough for you and somehow you are curious about why I moved to industry after so many years in academia. Although I am sure this event has a p-value &amp;gt; 0.05 , then &lt;a href=&#34;https://www.americanscientist.org/article/the-statistical-crisis-in-science&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;del&gt;is not significant.&lt;/del&gt; &lt;/a&gt;(wink wink)&lt;/p&gt;
&lt;p&gt;But if you know me a little bit, you may be surprised about this change in my career. It was a difficult decision for me, indeed. Somehow, I see this as a no turning back point, maybe is not totally true.  I have advocated, so many times, that my reason to stay in academia is that there are more chances to help each other, to create open-source resources, to move forward together… that somehow, moving to industry is the opposite of all that.&lt;/p&gt;
&lt;p&gt;However, academia couldn’t give me more, and I didn&amp;rsquo;t feel I was giving more. I decided a while ago to give up on a tenured career and dedicated many years to work inside a core facility at HSPH. I met awesome people, I learned from the best, I got to work with really amazing data…but there is a price for that. Being mainly an analyst made me see some parts that weren’t that nice. I realized many researchers will see you as a machine of producing data/figures/tables. They only care about that figure that will show the reviewer they were right. I saw how I couldn’t get into the project more than for a &amp;lsquo;quick&amp;rsquo; analysis of the data, without getting into the biology or the goal of the project.&lt;/p&gt;
&lt;p&gt;Not only that, but I realized I hadn’t a future, I would be stuck forever in that position, it was a senior position, but I really want to move forward and up. And after my second try at MIT, in another Bioinformatics core, I didn’t see that coming any time soon.&lt;/p&gt;
&lt;p&gt;It was time to think about why I am in the science business. Somehow, when I was young, I felt attracted to this world. I forgot about why, but what I liked was to work with people, together, to understand the molecular biology of a system. There was something else, it needed to be something that I believed in.&lt;/p&gt;
&lt;p&gt;And this is when &lt;a href=&#34;https://www.egenesisbio.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eGenesis Bio - Engineering Life&lt;/a&gt; came into my sight. The vision is simple: stop people dying because of a lack of compatible organs. The solution is almost science fiction: genome editing on pigs to clone them and use those organs in humans.&lt;/p&gt;
&lt;p&gt;I went to meet them, and I found a wonderful team and a challenging project. It was time to decide, and it was hard. Curiously, the main reasons that were stopping for saying yes, were mainly related to fear. A fear that the system put on me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need to publish &lt;em&gt;Nature&lt;/em&gt;, you need to be known on twitter, to be invited to conferences… otherwise, you won’t move forward in your career, you won’t have a good job.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And yes, I don’t have first-author papers in &lt;em&gt;Nature&lt;/em&gt;, I am not &lt;del&gt;famous on twitter,&lt;/del&gt; I am not invited to conferences, and leaving academia means I will never be that, for sure. I felt like a failure. Because I didn’t get any of that, and I will never get it. And somehow, I ended up thinking that was the only way to measure success.&lt;/p&gt;
&lt;p&gt;Luckily me, I read this book I had since months ago: &lt;a href=&#34;https://www.amazon.com/dp/1524762334/ref=cm_sw_em_r_mt_dp_U_hlNLDb98S9NTP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Brave, Not Perfect: Reshma Saujani&lt;/a&gt;, and helped me to see that feeling, those thoughts, as something external and not something that was part of me. At this point, I really wanted to forget about all the pressure I had on my shoulders and do just my job, my job on something that I consider relevant, and with the people I want to be.&lt;/p&gt;
&lt;p&gt;So, of course, I decided to move on. If the only reason why you won’t make a change is because of fear to fail/change/future, then you should definitely do it. (&lt;em&gt;read the book, seriously&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;In summary, I got to meet myself again, after so many years doing what the system has told me to do to get a good job, and have a future. I remembered what is my passion, I remembered to believe in myself, and let life to reward my decisions differently (this I will know in a year or so).&lt;/p&gt;
&lt;p&gt;Some other things I did meanwhile I was in this phase:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Write my research, teaching and diversity statements and apply for Associate Professors to 5 different positions to 5 different universities. I didn’t pass any filter.
&lt;ul&gt;
&lt;li&gt;Good mental exercise, yes, I know, 5 positions are nothing, you should apply to 30, or that was the main advice I got.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;I explored to change totally my career, as a project manager or data scientist in a non-biomedical field.
&lt;ul&gt;
&lt;li&gt;I took some courses, and I didn’t feel the click that I expect when you are in the right place.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;I felt miserable and with the lowest self-esteem in my life.
&lt;ul&gt;
&lt;li&gt;I started climbing indoors and working out with a personal trainer. All those negative feelings went away with time. Now I can do 2 pulls-up in a row for the first time in my life at the age of 37.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Single-cell cloning of human T-cell lines reveals clonal variation in cell death responses to chemotherapeutics.</title>
      <link>http://lpantano.github.io/publication/hanlon-2019/</link>
      <pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/hanlon-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>kallisto-bustools</title>
      <link>http://lpantano.github.io/post/2019/2019-07-19-kallisto-bustools/</link>
      <pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/post/2019/2019-07-19-kallisto-bustools/</guid>
      <description>&lt;pre&gt;&lt;code&gt;       JobID                        JobName      NCPUS     MaxRSS     AveRSS  Elapsed
------------ ------------------------------ ---------- ---------- ---------- ----------

14150319                             index          2     91.06G          0   01:26:32

14153823                          kallisto          2     67.28G     65.34G   00:59:35

14156768                       bus-correct          4      1.19G      1.19G   00:01:29

14156812                  bus-capture-cdna          4     16.16G     10.22G   00:07:59

14156835                bus-capture-intron          4     16.27G     16.27G   00:06:54
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>How to set up cellranger to make your hpc admin happy</title>
      <link>http://lpantano.github.io/post/2019/2019-07-12-cellranger-efficiency-in-hpc-copy/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/post/2019/2019-07-12-cellranger-efficiency-in-hpc-copy/</guid>
      <description>&lt;p&gt;I found myself to force to use &lt;a href=&#34;https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/advanced/cluster-mode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cellranger&lt;/a&gt;. Meanwhile it helps a lot to
run from &lt;a href=&#34;https://www.illumina.com/informatics/sequencing-data-analysis/sequence-file-formats.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bcl&lt;/a&gt; files to single cell counts matrixes, I discovered that is
quite difficult to control many options related to optimization.&lt;/p&gt;
&lt;p&gt;I have to run more than 200 samples in a short time of period. In my current
position at MIT, I joined the OpenMind cluster in the McGovern institute. I was
pleased to find a very flexible cluster, but as any other cluster you need to
respect other users.&lt;/p&gt;
&lt;p&gt;My samples are human samples, so I need a lot of memory so &lt;a href=&#34;https://github.com/alexdobin/STAR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;STAR&lt;/a&gt; can run. The
command line is easy to set up:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cellranger count --id=SAMPLE --transcriptome=GRCh38_pre_mRNA --fastqs=PATH2FASTQS --sample=SAMPLE&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Of course, that is in local mode. If you want to set up a job to a cluster,
it would look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
#SBATCH -N 1
#SBATCH -c 6
#SBATCH --mem=12000
#SBATCH -t 0-48:00:00
#SBATCH -J cellr
#SBATCH -e job-counts.e
#SBATCH -o job-counts.o
## SBATCH --mail-type=END,FAIL # this line is commented
## SBATCH --mail-user=user@mit.edu  # this line is commented

cellranger count --id=SAMPLE --transcriptome=GRCh38_pre_mRNA \
          --fastqs=PATH2FASTQS --sample=SAMPLE \
          --localcores=6 --localmem=120

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The main problem with that is you are using 120G during all the process that could
go to 1-2 days.&lt;/p&gt;
&lt;p&gt;I discovered that you can setup the &lt;code&gt; cluster&lt;/code&gt; mode to make &lt;code&gt;cellranger&lt;/code&gt; to send
jobs to the cluster. However, &lt;code&gt;slurm&lt;/code&gt; is not a option to the documentation, BUT
you can specify a template file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
#SBATCH -J __MRO_JOB_NAME__
#SBATCH -N 1
#SBATCH -c __MRO_THREADS__
#SBATCH --mem=__MRO_MEM_GB__G
#SBATCH -o __MRO_STDOUT__
#SBATCH -e __MRO_STDERR__
#SBATCH -t 0-48:00:00
#SBATCH --qos=&amp;quot;normal&amp;quot;

 __MRO_CMD__
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The command would look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cellranger count --id=SAMPLE --transcriptome=GRCh38_pre_mRNA \
          --fastqs=PATH2FASTQS --sample=SAMPLE \
          --jobmode=slurm.template \
          --maxjobs=3 --jobinterval=1000

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I was feeling victory, ha ha ha, BUT I saw that the &lt;code&gt;ALIGN&lt;/code&gt; step was requesting
220G of memory&amp;hellip;. WHAT!!!!!????? or better &lt;a href=&#34;https://www.destroyallsoftware.com/talks/wat&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WATTT????!!!!!&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt;: this is set up during genome generation with the parameters:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
    --memgb=&amp;lt;num&amp;gt;       Maximum memory (GB) used when aligning reads with STAR.
                          Defaults to 16.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;note&lt;/strong&gt;: default is 16G but if I use that then my jobs are cancelled because using more memory than requested, as I expected considering STAR needs more than that for human genome.&lt;/p&gt;
&lt;p&gt;I guess I didn&amp;rsquo;t look at the first place I should have looked, but it took me
some time to discovered that the memory is coming from a file in the reference
genome folder:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat GRCh38_pre_mRNA/reference.json
{
    &amp;quot;fasta_hash&amp;quot;: &amp;quot;954a9c3916ef1544c9358445440b9683fc061c71&amp;quot;,
    &amp;quot;genomes&amp;quot;: [
        &amp;quot;GRCh38_pre_mRNA&amp;quot;
    ],
    &amp;quot;gtf_hash&amp;quot;: &amp;quot;12aae438159b35282adaf643cca4dc5887b0448a&amp;quot;,
    &amp;quot;input_fasta_files&amp;quot;: [
        &amp;quot;Homo_sapiens.GRCh38.dna.toplevel.fa&amp;quot;
    ],
    &amp;quot;input_gtf_files&amp;quot;: [
        &amp;quot;GRC38_preRNA.gtf&amp;quot;
    ],
    &amp;quot;mem_gb&amp;quot;: 220,
    &amp;quot;mkref_version&amp;quot;: &amp;quot;3.0.2&amp;quot;,
    &amp;quot;threads&amp;quot;: 24,
    &amp;quot;version&amp;quot;: null
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I realized that when I found, after 100 &lt;code&gt;ls/cat/less/grep&lt;/code&gt;, this file with these
lines of code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cellranger-3.0.2/cellranger-cs/3.0.2/lib/python/cellranger/utils.py
def _load_reference_metadata_file(reference_path):
    reference_metadata_file = os.path.join(reference_path, cr_constants.REFERENCE_METADATA_FILE)
    with open(reference_metadata_file, &#39;r&#39;) as f:
        return json.load(f)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, easy peasy, I changed that to 110. I relaunched the job I was using to test,
and found that it was still setting up 220G&amp;hellip;WHY!?!!? well, it seems if you relaunch
in a step where the alignment has already begun, there is a cache for the resources.
So after more time trying to figure out this and asking myself, why I decided my
career path to be bioinformatics, I tried a fresh start and&amp;hellip;IT WORKED.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;How happy one can be to see a job requesting the expected resources.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Incredible happy!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I went a step further, and looked how much memory actually it was using during the
alignment step, and I saw that actually only needs 64G, so I updated to 72G, to
gain more karma from the HPC world.&lt;/p&gt;
&lt;p&gt;There is one more thing, that will set jobs of 72G and 4 cores, if you want to
increase the number of cores, then use this option &lt;code&gt;--mempercore 6&lt;/code&gt; or whatever number
that you want: &lt;code&gt;mempercore = 72G/final_cores&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;workflow&#34;&gt;Workflow&lt;/h2&gt;
&lt;p&gt;Finally, I felt that I was doing my best to behave and avoid making angry other
people using the hpc. The final setup looks like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;meta-script to send all the samples to a master job: &lt;code&gt;runner.sh&lt;/code&gt;. It accepts
a file where first column is &lt;code&gt;sample name&lt;/code&gt; and second column is &lt;code&gt;fastq_path&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;set -o pipefail  # trace ERR through pipes
set -o errtrace  # trace ERR through &#39;time command&#39; and other functions
set -o nounset   ## set -u : exit the script if you try to use an uninitialised variable
set -o errexit   ## set -e : exit the script if any statement returns a non-true return value
# set -v # you can uncomment all these lines to have a better debugging
# set -x
# export PS4=&#39;+(${BASH_SOURCE}:${LINENO}): ${FUNCNAME[0]:+${FUNCNAME[0]}(): }&#39;

while IFS=&amp;quot; &amp;quot; read -r sample paths

do

RUN=0
if [[ ! -e $sample/filtered_feature_bc_matrix.h5 ]]; then
    RUN=1 # run if the final output is not there yet
fi

if [[  -e  $sample/_lock ]]; then
    echo $sample is locked, please:
    echo rm $sample/_lock
    RUN=0 # but don&#39;t do anything if is locked
fi

if [[ $RUN == 1 ]]; then
    echo sbatch -J $sample -o logs/$sample.o -e logs/$sample.e scripts/om-counts-cluster.slurm $sample $paths
    sbatch -J $sample -o logs/$sample.o -e logs/$sample.e scripts/om-counts-cluster.slurm $sample $paths
fi

done &amp;lt; $1
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;SBATCH script with cellranger command: &lt;code&gt;counter.slurm&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash
#SBATCH -N 1
#SBATCH -c 1
#SBATCH --mem=6000
#SBATCH -t 0-48:00:00
# SBATCH -J &amp;quot;cellr-$1&amp;quot;
# SBATCH -e job-counts-$1.e
# SBATCH -o job-counts-$1.o
## SBATCH --mail-type=END,FAIL # this line is commented
## SBATCH --mail-user=user@mit.edu  # this line is commented

SCRIPTPATH=&amp;quot;PATHTOSCRIPTS&amp;quot;
cellranger count --id=$1 --transcriptome=GRCh38_pre_mRNA --fastqs=$2 --sample=$1 --jobmode=$SCRIPTPATH/slurm.template --maxjobs=3 --jobinterval=1000

if [ $? -eq 0 ]; then
    echo OK
    mv $1 results/.
else
    echo $1 FAIL
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;template script for &lt;code&gt;cellranger&lt;/code&gt; as shown above&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;other-tips&#34;&gt;Other tips&lt;/h3&gt;
&lt;p&gt;I used &lt;code&gt;mxjobs=3&lt;/code&gt; to avoid a lot of jobs. I am testing how things go, this could be spanned to bigger numbers.&lt;/p&gt;
&lt;p&gt;I used &lt;code&gt;jobinterval=1000&lt;/code&gt; to avoid sending jobs at the same time, just in case, but I don&amp;rsquo;t have any proof to support this.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;happiness in bioinformatics:&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Sex Differences in Adrenal Bmal1 Deletion-Induced Augmentation of Glucocorticoid Responses to Stress and ACTH in Mice.</title>
      <link>http://lpantano.github.io/publication/engeland-2019/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/engeland-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A High-Throughput Screening Identifies MicroRNA Inhibitors That Influence Neuronal Maintenance and/or Response to Oxidative Stress.</title>
      <link>http://lpantano.github.io/publication/pallarsalbanell-2019/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/pallarsalbanell-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multi omics analysis of fibrotic kidneys in two mouse models.</title>
      <link>http://lpantano.github.io/publication/pavkovic-2019/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/pavkovic-2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to set up public dataset analysis with bcbio-nextgen</title>
      <link>http://lpantano.github.io/post/2019/2019-04-05-how-to-setup-remote-samples-with-bcbio/</link>
      <pubDate>Fri, 05 Apr 2019 10:13:02 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2019/2019-04-05-how-to-setup-remote-samples-with-bcbio/</guid>
      <description>&lt;p&gt;We use &lt;a href=&#34;https://github.com/bcbio/bcbio-nextgen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bcbio-nextgen&lt;/a&gt; for the analysis of sequencing data, mainly, (sc)RNAseq,
smallRNAseq, DNASeq and ChIPSeq. It is not rare that we get collaborators who
wants to re-analyze public data-set.&lt;/p&gt;
&lt;p&gt;Inside &lt;code&gt;bcbio&lt;/code&gt;, we have &lt;a href=&#34;https://bcbio-nextgen.readthedocs.io/en/latest/contents/configuration.html#multiple-files-per-sample&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;bcbio_prepare_samples.py&lt;/code&gt;&lt;/a&gt;
to help to merge multiple
files that belong to the same sample into one file to make easier the configuration
of &lt;strong&gt;bcbio&lt;/strong&gt;. We extended this script to pull down data from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GEO&lt;/a&gt; and
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/sra&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SRA&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;If you have &lt;strong&gt;bcbio&lt;/strong&gt;. installed, you can create a &lt;code&gt;example.csv&lt;/code&gt; file like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;samplenames,description
GSM3508215,HEK293T
SRR8311268,Hela
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bcbio_prepare_samples.py --csv example.csv --out fastq
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will download and create all the files inside &lt;code&gt;fastq&lt;/code&gt; folder. If the samples
is paired-end, it will generated the two associated files: R1 and R2.&lt;/p&gt;
&lt;p&gt;Cool options to use:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--remove-source&lt;/code&gt;: if you want to keep only final files.&lt;/li&gt;
&lt;li&gt;you can use full FTP addresses as well under &lt;code&gt;samplenames&lt;/code&gt; column&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nextflow.io/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NextFlow&lt;/a&gt; accepts these SRA ids as well, &lt;a href=&#34;https://www.nextflow.io/blog/2019/release-19.03.0-edge.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;take a look&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And &lt;a href=&#34;https://ewels.github.io/sra-explorer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sra-explorer&lt;/a&gt; from &lt;a href=&#34;https://github.com/ewels&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Phil Ewels&lt;/a&gt;
will create a bash script to download the FASTQ files and It has a great search engine where
you can use any of these terms to find your public data:
&lt;code&gt;GSE30567, SRP043510, PRJEB8073, ERP009109 or human liver miRNA.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The only advantage of &lt;strong&gt;bcbio&lt;/strong&gt; is that in the case of multiple files associated to the same
sample, it will merge the files together. For instance, if you search in &lt;strong&gt;sra-explorer&lt;/strong&gt; for this&lt;br&gt;
term: &lt;code&gt;GSM2598386&lt;/code&gt;, you see that multiple files. &lt;strong&gt;bcbio&lt;/strong&gt;. will merge all  of them into one and
you can run your pipeline directly afterwards. And pretty convenient if you
use any of the &lt;strong&gt;bcbio&lt;/strong&gt; pipelines :).&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;happiness in bioinformatics: when your collaborators give you  a CSV file
with all the metadata for your raw data and they match.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>miRNA variants (isomiRs): real molecules or sequencing artifacts?</title>
      <link>http://lpantano.github.io/talk/bioclub2019/</link>
      <pubDate>Sat, 09 Feb 2019 00:00:00 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/bioclub2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evolutionary and functional impact of common polymorphic inversions in the human genome</title>
      <link>http://lpantano.github.io/publication/giner-2019-evolutionary/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/giner-2019-evolutionary/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sex-dependent changes in miRNA expression in the bed nucleus of the stria terminalis following stress</title>
      <link>http://lpantano.github.io/publication/mavrikaki-2019-sex/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/mavrikaki-2019-sex/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MiRNA Wars: The isomiRs menance</title>
      <link>http://lpantano.github.io/talk/big2018/</link>
      <pubDate>Sun, 02 Dec 2018 15:06:12 -0500</pubDate>
      <guid>http://lpantano.github.io/talk/big2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Unification of miRNA and isomiR research: the mirGFF3 format and the mirtop API</title>
      <link>http://lpantano.github.io/publication/desvignes-2018/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/desvignes-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Get colors for your heatmap annotation</title>
      <link>http://lpantano.github.io/post/legacy/2018-09-21-colors-for-annotations-for-heatmaps/</link>
      <pubDate>Fri, 21 Sep 2018 10:13:02 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2018-09-21-colors-for-annotations-for-heatmaps/</guid>
      <description>&lt;p&gt;This post will show how to configure quickly the colors for the annotation of rows/columns that go on top or on the side of a heatmap.&lt;/p&gt;
&lt;p&gt;I normally use &lt;code&gt;pheatmap&lt;/code&gt; a lot. Recently I discovered &lt;code&gt;ComplexHeatmap&lt;/code&gt;. In both cases I spend always sometime changing the colors of the annotations. I ended up coding a function inside my package &lt;code&gt;DEGreport&lt;/code&gt; to do that.&lt;/p&gt;
&lt;p&gt;Given a data.frame with metadata data information will do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;white-black scale for numerical variables&lt;/li&gt;
&lt;li&gt;blue-orange for categorical values with only two categories&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Set2&lt;/code&gt; palette for categorical values with more than two categories&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All three color sets can be changed using the &lt;a href=&#34;http://lpantano.github.io/DEGreport/reference/degColors.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;parameters function&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(DEGreport)
library(stemHypoxia)
data(stemHypoxia)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am going to use this &lt;a href=&#34;https://bioconductor.org/packages/release/data/experiment/html/stemHypoxia.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stemcell experiment dataset&lt;/a&gt; I found randomly in Bioconductor page.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;exp = as.matrix(M[,3:30])
rownames(exp) = M[,2]
rownames(design) = colnames(exp)
design = design[,c(1:2)]
design$time = as.factor(design$time)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;rsquo;ll find the most variable genes.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;most_variable = names(tail(sort(apply(exp, 1, sd)), 1000))
design$mean_gene = colMeans(exp[most_variable,])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And we can plot the heatmap with new colors with need to specify each variable at a time.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(pheatmap)
pheatmap(exp[most_variable,], scale = &amp;quot;row&amp;quot;, show_rownames = FALSE,
         annotation_col = design,
         annotation_colors = degColors(design))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/lpantano/mypubs/raw/master/code-blog/degcolor/degcolors_files/figure-markdown_github/unnamed-chunk-4-1.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;If you use &lt;code&gt;ComplexHeatmap&lt;/code&gt; you can activate &lt;code&gt;col_fun = TRUE&lt;/code&gt; to get it working.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R Session&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;devtools::session_info()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: &#39;DESCRIPTION&#39; file has an &#39;Encoding&#39; field and re-encoding is not
## possible

## Session info -------------------------------------------------------------

##  setting  value
##  version  R version 3.5.1 (2018-07-02)
##  system   x86_64, darwin15.6.0
##  ui       X11
##  language (EN)
##  collate  en_US.UTF-8
##  tz       America/New_York
##  date     2018-09-21

## Packages -----------------------------------------------------------------

##  package              * version   date       source
##  acepack                1.4.1     2016-10-29 cran (@1.4.1)
##  annotate               1.58.0    2018-05-01 cran (@1.58.0)
##  AnnotationDbi          1.42.1    2018-05-08 Bioconductor
##  assertthat             0.2.0     2017-04-11 CRAN (R 3.5.0)
##  backports              1.1.2     2017-12-13 CRAN (R 3.5.0)
##  base                 * 3.5.1     2018-07-05 local
##  base64enc              0.1-3     2015-07-28 CRAN (R 3.5.0)
##  bindr                  0.1.1     2018-03-13 CRAN (R 3.5.0)
##  bindrcpp               0.2.2     2018-03-29 CRAN (R 3.5.0)
##  Biobase                2.40.0    2018-05-01 Bioconductor
##  BiocGenerics           0.26.0    2018-05-01 Bioconductor
##  BiocParallel           1.14.2    2018-07-08 cran (@1.14.2)
##  bit                    1.1-14    2018-05-29 CRAN (R 3.5.0)
##  bit64                  0.9-7     2017-05-08 CRAN (R 3.5.0)
##  bitops                 1.0-6     2013-08-17 cran (@1.0-6)
##  blob                   1.1.1     2018-03-25 CRAN (R 3.5.0)
##  broom                  0.5.0     2018-07-17 CRAN (R 3.5.0)
##  checkmate              1.8.5     2017-10-24 cran (@1.8.5)
##  circlize               0.4.4     2018-06-10 cran (@0.4.4)
##  cluster                2.0.7-1   2018-04-13 CRAN (R 3.5.1)
##  colorspace             1.3-2     2016-12-14 CRAN (R 3.5.0)
##  compiler               3.5.1     2018-07-05 local
##  ComplexHeatmap         1.18.1    2018-06-19 cran (@1.18.1)
##  ConsensusClusterPlus   1.44.0    2018-05-01 cran (@1.44.0)
##  cowplot                0.9.3     2018-07-15 cran (@0.9.3)
##  crayon                 1.3.4     2017-09-16 CRAN (R 3.5.0)
##  data.table             1.11.4    2018-05-27 cran (@1.11.4)
##  datasets             * 3.5.1     2018-07-05 local
##  DBI                    1.0.0     2018-05-02 CRAN (R 3.5.0)
##  DEGreport            * 1.17.5    2018-09-04 local (lpantano/DEGreport@NA)
##  DelayedArray           0.6.5     2018-08-15 cran (@0.6.5)
##  DESeq2                 1.20.0    2018-05-01 Bioconductor
##  devtools               1.13.6    2018-06-27 CRAN (R 3.5.0)
##  digest                 0.6.16    2018-08-22 CRAN (R 3.5.0)
##  dplyr                  0.7.6     2018-06-29 CRAN (R 3.5.1)
##  edgeR                  3.22.3    2018-06-21 cran (@3.22.3)
##  evaluate               0.11      2018-07-17 CRAN (R 3.5.0)
##  foreign                0.8-71    2018-07-20 CRAN (R 3.5.0)
##  Formula                1.2-3     2018-05-03 cran (@1.2-3)
##  genefilter             1.62.0    2018-05-01 cran (@1.62.0)
##  geneplotter            1.58.0    2018-05-01 cran (@1.58.0)
##  GenomeInfoDb           1.16.0    2018-05-01 cran (@1.16.0)
##  GenomeInfoDbData       1.1.0     2018-08-31 Bioconductor
##  GenomicRanges          1.32.6    2018-07-20 cran (@1.32.6)
##  GetoptLong             0.1.7     2018-06-10 cran (@0.1.7)
##  ggdendro               0.1-20    2016-04-27 cran (@0.1-20)
##  ggplot2                3.0.0     2018-07-03 CRAN (R 3.5.0)
##  ggrepel                0.8.0     2018-05-09 cran (@0.8.0)
##  GlobalOptions          0.1.0     2018-06-09 cran (@0.1.0)
##  glue                   1.3.0     2018-07-17 CRAN (R 3.5.0)
##  graphics             * 3.5.1     2018-07-05 local
##  grDevices            * 3.5.1     2018-07-05 local
##  grid                   3.5.1     2018-07-05 local
##  gridExtra              2.3       2017-09-09 cran (@2.3)
##  gtable                 0.2.0     2016-02-26 CRAN (R 3.5.0)
##  Hmisc                  4.1-1     2018-01-03 cran (@4.1-1)
##  htmlTable              1.12      2018-05-26 cran (@1.12)
##  htmltools              0.3.6     2017-04-28 CRAN (R 3.5.0)
##  htmlwidgets            1.2       2018-04-19 cran (@1.2)
##  IRanges                2.14.11   2018-08-24 Bioconductor
##  knitr                  1.20      2018-02-20 CRAN (R 3.5.0)
##  lasso2                 1.2-19    2014-05-31 cran (@1.2-19)
##  lattice                0.20-35   2017-03-25 CRAN (R 3.5.1)
##  latticeExtra           0.6-28    2016-02-09 cran (@0.6-28)
##  lazyeval               0.2.1     2017-10-29 CRAN (R 3.5.0)
##  limma                  3.36.3    2018-08-25 cran (@3.36.3)
##  locfit                 1.5-9.1   2013-04-20 cran (@1.5-9.1)
##  logging                0.7-103   2013-04-12 cran (@0.7-103)
##  magrittr               1.5       2014-11-22 CRAN (R 3.5.0)
##  MASS                   7.3-50    2018-04-30 CRAN (R 3.5.1)
##  Matrix                 1.2-14    2018-04-13 CRAN (R 3.5.1)
##  matrixStats            0.54.0    2018-07-23 cran (@0.54.0)
##  memoise                1.1.0     2017-04-21 CRAN (R 3.5.0)
##  methods              * 3.5.1     2018-07-05 local
##  mnormt                 1.5-5     2016-10-15 cran (@1.5-5)
##  munsell                0.5.0     2018-06-12 CRAN (R 3.5.0)
##  nlme                   3.1-137   2018-04-07 CRAN (R 3.5.1)
##  nnet                   7.3-12    2016-02-02 CRAN (R 3.5.1)
##  Nozzle.R1              1.1-1     2013-05-15 cran (@1.1-1)
##  parallel               3.5.1     2018-07-05 local
##  pheatmap             * 1.0.10    2018-05-19 CRAN (R 3.5.0)
##  pillar                 1.3.0     2018-07-14 CRAN (R 3.5.0)
##  pkgconfig              2.0.2     2018-08-16 CRAN (R 3.5.0)
##  plyr                   1.8.4     2016-06-08 CRAN (R 3.5.0)
##  psych                  1.8.4     2018-05-06 cran (@1.8.4)
##  purrr                  0.2.5     2018-05-29 CRAN (R 3.5.0)
##  R6                     2.2.2     2017-06-17 CRAN (R 3.5.0)
##  RColorBrewer           1.1-2     2014-12-07 CRAN (R 3.5.0)
##  Rcpp                   0.12.18   2018-07-23 CRAN (R 3.5.0)
##  RCurl                  1.95-4.11 2018-07-15 cran (@1.95-4.)
##  reshape                0.8.7     2017-08-06 cran (@0.8.7)
##  rjson                  0.2.20    2018-06-08 cran (@0.2.20)
##  rlang                  0.2.2     2018-08-16 CRAN (R 3.5.0)
##  rmarkdown              1.10      2018-06-11 CRAN (R 3.5.0)
##  rpart                  4.1-13    2018-02-23 CRAN (R 3.5.1)
##  rprojroot              1.3-2     2018-01-03 CRAN (R 3.5.0)
##  RSQLite                2.1.1     2018-05-06 CRAN (R 3.5.0)
##  rstudioapi             0.7       2017-09-07 CRAN (R 3.5.0)
##  S4Vectors              0.18.3    2018-06-08 Bioconductor
##  scales                 1.0.0     2018-08-09 CRAN (R 3.5.0)
##  shape                  1.4.4     2018-02-07 cran (@1.4.4)
##  splines                3.5.1     2018-07-05 local
##  stats                * 3.5.1     2018-07-05 local
##  stats4                 3.5.1     2018-07-05 local
##  stemHypoxia          * 1.16.0    2018-09-21 Bioconductor
##  stringi                1.2.4     2018-07-20 CRAN (R 3.5.0)
##  stringr                1.3.1     2018-05-10 CRAN (R 3.5.0)
##  SummarizedExperiment   1.10.1    2018-05-11 Bioconductor
##  survival               2.42-6    2018-07-13 CRAN (R 3.5.0)
##  tibble                 1.4.2     2018-01-22 CRAN (R 3.5.0)
##  tidyr                  0.8.1     2018-05-18 CRAN (R 3.5.0)
##  tidyselect             0.2.4     2018-02-26 CRAN (R 3.5.0)
##  tools                  3.5.1     2018-07-05 local
##  utils                * 3.5.1     2018-07-05 local
##  withr                  2.1.2     2018-03-15 CRAN (R 3.5.0)
##  XML                    3.98-1.16 2018-08-19 cran (@3.98-1.)
##  xtable                 1.8-3     2018-08-29 cran (@1.8-3)
##  XVector                0.20.0    2018-05-01 cran (@0.20.0)
##  yaml                   2.2.0     2018-07-25 CRAN (R 3.5.0)
##  zlibbioc               1.26.0    2018-05-01 cran (@1.26.0)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>How to plot miRNA, gene expression and functional analysis together</title>
      <link>http://lpantano.github.io/post/legacy/2018-08-13-omic-figure-for-mirna-gene-functional-data/</link>
      <pubDate>Sun, 12 Aug 2018 09:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2018-08-13-omic-figure-for-mirna-gene-functional-data/</guid>
      <description>&lt;p&gt;This post should show you an easy way to get the following data type
integrated into a figure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;functional enrichment analysis&lt;/li&gt;
&lt;li&gt;gene expression data from any technology&lt;/li&gt;
&lt;li&gt;miRNA expression data from any technology&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I am using the function &lt;code&gt;isoNetwork&lt;/code&gt; from the package &lt;code&gt;isomiRs&lt;/code&gt;, that of
course is developed by me :) My ego is not that big, it is just I wanted
a figure showing that information, and I couldn&amp;rsquo;t find any at a time,
but if you know any, tweet me about it to @lopantano.&lt;/p&gt;
&lt;p&gt;This function needs some pre-computed information, like the normalized
expression and the targeted genes by miRNAs. Normally, the significant
genes and miRNAs from a differentially expression analysis would do it.&lt;/p&gt;
&lt;p&gt;The first requirement is two have these two datasets into a
SummarizedExperiment object As an example, I am using the published data
from Folic Acid Mouse model (GSE65267) that has been analyzed with
bcbio-nextgen pipeline and bcbioRNASeq package.&lt;/p&gt;
&lt;p&gt;I saved these analysis into an R object that contains:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fa_mrna: gene expression&lt;/li&gt;
&lt;li&gt;fa_mirna: miRNA expression&lt;/li&gt;
&lt;li&gt;fa_cold: metadata&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;From that, I ran DESeq2 to get the significant genes and miRNAs from the
comparison day14 vs day0 (normal).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R&amp;gt; load(&amp;quot;fa_isonetwork.rda&amp;quot;)
R&amp;gt; library(isomiRs)
R&amp;gt; library(DESeq2)
R&amp;gt; library(SummarizedExperiment)
R&amp;gt;
R&amp;gt; mi_cold = fa_cold[colnames(fa_mirna), , drop = F]
R&amp;gt; mi_dse = DESeqDataSetFromMatrix(round(2^fa_mirna), mi_cold, design = ~day)
R&amp;gt; mi_dse = DESeq(mi_dse)
R&amp;gt; mi_res = results(mi_dse, name = &amp;quot;day_day14_vs_normal&amp;quot;)
R&amp;gt; mi_res = mi_res[!is.na(mi_res$padj), ]
R&amp;gt; mi_top = row.names(mi_res[mi_res$padj &amp;lt; 0.05, ])
R&amp;gt; mi_rse = SummarizedExperiment(assays = SimpleList(norm = fa_mirna), colData = mi_cold,
+     metadata = list(sign = mi_top))
R&amp;gt;
R&amp;gt; m_cold = fa_cold[colnames(fa_mrna), , drop = F]
R&amp;gt; m_dse = DESeqDataSetFromMatrix(round(2^fa_mrna), m_cold, design = ~day)
R&amp;gt; m_dse = DESeq(m_dse)
R&amp;gt; m_res = results(m_dse, name = &amp;quot;day_day14_vs_normal&amp;quot;)
R&amp;gt; m_res = m_res[!is.na(m_res$padj), ]
R&amp;gt; m_top = row.names(m_res[m_res$padj &amp;lt; 0.05, ])
R&amp;gt; m_rse = SummarizedExperiment(assays = SimpleList(norm = fa_mrna), colData = m_cold,
+     metadata = list(sign = m_top))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After that, I ran the functional analysis with &lt;a href=&#34;http://bioconductor.org/packages/release/bioc/html/clusterProfiler.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;clusterProfiler&lt;/code&gt; Bioc
package&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R&amp;gt; library(org.Mm.eg.db)
R&amp;gt; library(clusterProfiler)
R&amp;gt;
R&amp;gt;
R&amp;gt; ego &amp;lt;- enrichGO(m_top, org.Mm.eg.db, &amp;quot;ENSEMBL&amp;quot;, ont = &amp;quot;MF&amp;quot;, universe = rownames(m_res))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Actually, it could be anything as far as the table have the same naming
that the one coming from this package.&lt;/p&gt;
&lt;p&gt;Last step before the real integration analysis, is to get the predicted
targets of the miRNA. This can be done with any package as far as you
get a table with two columns: gene and mirna.&lt;/p&gt;
&lt;p&gt;I used two options, one using the already implemented code in the
package (that uses targetscan database):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R&amp;gt; library(targetscan.Mm.eg.db)
R&amp;gt; m2t = mirna2targetscan(mi_top, species = &amp;quot;mmu&amp;quot;, org = org.Mm.eg.db, keytype = &amp;quot;ENSEMBL&amp;quot;)
R&amp;gt;
R&amp;gt; mirna_targets = findTargets(mi_rse, m_rse, m2t[, c(&amp;quot;ENSEMBL&amp;quot;, &amp;quot;mir&amp;quot;)], summarize = &amp;quot;day&amp;quot;,
+     min_cor = -0.7)

## Dimmension of cor matrix: 49 5233
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or using the function &lt;code&gt;get_multimir&lt;/code&gt; implemented on &lt;a href=&#34;http://bioconductor.org/packages/release/bioc/html/multiMir.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;multiMiR&lt;/code&gt; Bioc
package&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R&amp;gt; library(multiMiR)
R&amp;gt; multimir_results &amp;lt;- get_multimir(org = &amp;quot;mmu&amp;quot;, mirna = mi_top, table = &amp;quot;validated&amp;quot;,
+     summary = TRUE)
R&amp;gt;
R&amp;gt; library(magrittr)
R&amp;gt; m2t_multimir = slot(multimir_results, &amp;quot;data&amp;quot;)[, c(&amp;quot;target_ensembl&amp;quot;, &amp;quot;mature_mirna_id&amp;quot;)] %&amp;gt;%
+     dplyr::filter(target_ensembl != &amp;quot;&amp;quot;) %&amp;gt;% dplyr::distinct()
R&amp;gt;
R&amp;gt; mirna_targets = findTargets(mi_rse, m_rse, m2t_multimir, summarize = &amp;quot;day&amp;quot;,
+     min_cor = -0.7)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In both cases, I ran &lt;code&gt;findTargets&lt;/code&gt; to use the expression data to make
sure the correlation between the miRNA and predicted gene is negative
since is the known biological function of miRNAs, being negative
modulators.&lt;/p&gt;
&lt;p&gt;Finally, we use &lt;code&gt;isoNetwork&lt;/code&gt; to put all the data together, and
&lt;code&gt;isoPlotNet&lt;/code&gt; to create the final figure with all information.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;R&amp;gt; data &amp;lt;- isoNetwork(mi_rse, m_rse, min_fc = 0.1, summarize = &amp;quot;day&amp;quot;, target = mirna_targets,
+     enrich = ego)

## Dimmension of cor matrix: 49 305

R&amp;gt; isoPlotNet(data, minGenes = 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://github.com/lpantano/mypubs/raw/master/code-blog/isonetwork/post_files/figure-markdown_strict/unnamed-chunk-5-1.png&#34; /&gt;
&lt;p&gt;It is an easy way to spot what pathways contain genes that are targeted
by miRNAs.&lt;/p&gt;
&lt;p&gt;Note that this function won&amp;rsquo;t indicate if a pathway is enriched on miRNA
targets. It shows how these three different data set can be put together
to explore the relationship among them.&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;self-control in bioinformatics: be nice to your collaborator when
they can not open a TSV file with excel.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>The circulating metabolome of human starvation</title>
      <link>http://lpantano.github.io/publication/steinhauser-2018/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/steinhauser-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>miRTOP: An open source community project for the development of a unified format file for miRNA data</title>
      <link>http://lpantano.github.io/talk/bosc2018/</link>
      <pubDate>Wed, 27 Jun 2018 13:13:02 -0900</pubDate>
      <guid>http://lpantano.github.io/talk/bosc2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Circulating miRNAs, isomiRs and small RNA clusters in human plasma and breast milk</title>
      <link>http://lpantano.github.io/publication/rubio-2018/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/rubio-2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>bcbioRNASeq: R package for bcbio RNA-seq analysis</title>
      <link>http://lpantano.github.io/publication/steinbaugh-2017/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/steinbaugh-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DEGreport intro: a tolkit for DE analysis</title>
      <link>http://lpantano.github.io/tutorials/2017-09-13-degreport-intro-a-tolkit-for-de-analysis/</link>
      <pubDate>Wed, 13 Sep 2017 13:50:51 +0000</pubDate>
      <guid>http://lpantano.github.io/tutorials/2017-09-13-degreport-intro-a-tolkit-for-de-analysis/</guid>
      <description>&lt;h2 id=&#34;video-tutorial&#34;&gt;Video Tutorial&lt;/h2&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/95_kMyzxiVU?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.meetup.com/Cambridge-woman-developers-in-bioinformatics/events/242964863/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.meetup.com/Cambridge-woman-developers-in-bioinformatics/events/242964863/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;watch-on-youtube&#34;&gt;Watch on YouTube&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=95_kMyzxiVU&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;View on YouTube&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Subset of object creates bigger RDA file size than original object</title>
      <link>http://lpantano.github.io/post/legacy/2017-08-24-subset-object-creates-bigger-file/</link>
      <pubDate>Wed, 23 Aug 2017 17:50:01 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2017-08-24-subset-object-creates-bigger-file/</guid>
      <description>&lt;p&gt;This is a funny story, and I will try to tell you how I realized I don&amp;rsquo;t know anything about R in 400 words.&lt;/p&gt;
&lt;p&gt;I work at the Bioinformatic Core at Harvard TH School. People who know us, or collaborate with us, knows that we mainly use
&lt;a href=&#34;https://github.com/chapmanb/bcbio-nextgen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bcbio&lt;/a&gt; to analyze sequencing data (check it out, super cool tool).&lt;/p&gt;
&lt;p&gt;Something that we are working on is to load the data after &lt;code&gt;bcbio&lt;/code&gt; finishes into R to ease the downstream analysis.
For instance, for RNA-seq we have &lt;a href=&#34;https://github.com/hbc/bcbioRnaSeq&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bcbioRnaSeq&lt;/a&gt; and for small RNA-seq we have &lt;a href=&#34;https://github.com/lpantano/bcbioSmallRna&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bcbioSmallRna&lt;/a&gt;. In short,
these R packages make easy the task to load all the data generated by &lt;code&gt;bcbio&lt;/code&gt; and wrap many methods and functions to generate the most used figures/analysis.&lt;/p&gt;
&lt;p&gt;That is not the story. The story is that the &lt;code&gt;bcbioRNADataSet&lt;/code&gt; object in those packages contains all the data in order to make easy the use of different counts matrix,
or subset to a smaller samples/genes. For instance, the object contains the DDS object (&lt;a href=&#34;http://bioconductor.org/packages/devel/bioc/html/DESeq2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DESeq2&lt;/a&gt; &lt;code&gt;DESeqDataSet&lt;/code&gt;),
so we can use methods for this class or re-normalize at any point.&lt;/p&gt;
&lt;p&gt;Well, when we implemented the &lt;code&gt;[&lt;/code&gt; method (this allows to subset the object), we discovered that the
object coming from that method was twice as big when saving into an RDA file. For instance, if you have an object with 34K genes,
100 samples that would be 900Mb when saving, then you subset to 1000 genes and 8 samples, you would end up with a file being 1.6G.&lt;/p&gt;
&lt;p&gt;That is not nice, so I decided to play around. I don&amp;rsquo;t want you to read our code, because contains a lot of information, but feel free: &lt;a href=&#34;https://github.com/hbc/bcbioRnaseq/blob/master/R/methods-subset.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;subset&lt;/a&gt;. I value your time, so this is a &lt;a href=&#34;https://github.com/lpantano/mypubs/blob/master/examples/subsetObject/subset.R&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dummy example&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The examples mainly creates different objects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dummyBig: 10K genes, 100 samples&lt;/li&gt;
&lt;li&gt;dummySmall: 500 genes, 5 samples&lt;/li&gt;
&lt;li&gt;dummySilly: subset of dummyBig using a silly function to subset, same size than dummySmall&lt;/li&gt;
&lt;li&gt;dummySmart: subset of dummyBig using a smart function to subset, same size than dummySmall&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We should expect that &lt;code&gt;dummySilly&lt;/code&gt; and &lt;code&gt;dummySmart&lt;/code&gt; have a similar size than &lt;code&gt;dummySmall&lt;/code&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;This is the size of RDA files for each of them (size in Kb):&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;object&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;file&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;rdaSize&lt;/th&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;objSize&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;dummyBig&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;big.rda&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;2828.49 Kb&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;1588 Kb&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;dummySmall&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;micro.rda&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;24.19 Kb&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;42.6 Kb&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;dummySilly&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;microSilly.rda&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;4397.49 Kb&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;43.2 Kb&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;dummySmart&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;microSmart.rda&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;22.38 Kb&lt;/td&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;43.2 Kb&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;rdaSize is the size of the file using &lt;code&gt;save(obj, file = fileName.rda&lt;/code&gt; function. objSize is the size in memory in R using the function &lt;code&gt;format(object.size(obj))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;As you can see, &lt;code&gt;microSilly&lt;/code&gt; is almost twice the original data, but &lt;code&gt;microSmart&lt;/code&gt; is the expected size.&lt;/p&gt;
&lt;p&gt;I don&amp;rsquo;t know the exact reason, but the &lt;a href=&#34;https://github.com/lpantano/mypubs/blob/master/examples/subsetObject/subset.R#L52&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;chunk of code&lt;/a&gt; that made the trick was to create an internal function to be called inside the method to re-generate the &lt;a href=&#34;http://bioconductor.org/packages/devel/bioc/html/DESeq2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DESeq2&lt;/a&gt; object with the smaller size.&lt;/p&gt;
&lt;p&gt;I know there should be a better way to avoid this, but this worked. If you have any comment/advice post it &lt;a href=&#34;https://github.com/lpantano/mypubs/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. My R session is below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;honesty in bioinformatics: accept you develop without being an expert and that creates chaos.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;R version 3.4.1 (2017-06-30)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] parallel  stats4    methods   stats     graphics  grDevices utils
[8] datasets  base

other attached packages:
 [1] dplyr_0.7.2.9000           DESeq2_1.16.1
 [3] SummarizedExperiment_1.6.3 DelayedArray_0.2.7
 [5] matrixStats_0.52.2         Biobase_2.36.2
 [7] GenomicRanges_1.28.4       GenomeInfoDb_1.12.2
 [9] IRanges_2.10.2             S4Vectors_0.14.3
[11] BiocGenerics_0.22.0

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.12            locfit_1.5-9.1          lattice_0.20-35
 [4] assertthat_0.2.0        digest_0.6.12           R6_2.2.2
 [7] plyr_1.8.4              backports_1.1.0         acepack_1.4.1
[10] RSQLite_2.0             highr_0.6               ggplot2_2.2.1
[13] zlibbioc_1.22.0         rlang_0.1.2.9000        lazyeval_0.2.0
[16] data.table_1.10.4       annotate_1.54.0         blob_1.1.0
[19] rpart_4.1-11            Matrix_1.2-10           checkmate_1.8.2
[22] splines_3.4.1           BiocParallel_1.10.1     geneplotter_1.54.0
[25] stringr_1.2.0           foreign_0.8-69          htmlwidgets_0.8
[28] RCurl_1.95-4.8          bit_1.1-12              munsell_0.4.3
[31] compiler_3.4.1          pkgconfig_2.0.1         base64enc_0.1-3
[34] htmltools_0.3.6         nnet_7.3-12             tibble_1.3.3.9001
[37] gridExtra_2.2.1         htmlTable_1.9           GenomeInfoDbData_0.99.0
[40] Hmisc_4.0-3             XML_3.98-1.9            bitops_1.0-6
[43] grid_3.4.1              xtable_1.8-2            gtable_0.2.0
[46] DBI_0.7                 magrittr_1.5            scales_0.4.1
[49] stringi_1.1.5           XVector_0.16.0          genefilter_1.58.1
[52] bindrcpp_0.2            latticeExtra_0.6-28     Formula_1.2-1
[55] RColorBrewer_1.1-2      tools_3.4.1             bit64_0.9-7
[58] glue_1.1.1.9000         survival_2.41-3         AnnotationDbi_1.38.2
[61] colorspace_1.3-2        cluster_2.0.6           memoise_1.1.0
[64] bindr_0.1               knitr_1.17

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>DEGreport to plot nice RNA-seq figures</title>
      <link>http://lpantano.github.io/post/legacy/2017-03-20-degreport-rnaseq-figures/</link>
      <pubDate>Mon, 20 Mar 2017 17:50:01 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2017-03-20-degreport-rnaseq-figures/</guid>
      <description>&lt;p&gt;Differentially gene expression analysis with &lt;a href=&#34;https://en.wikipedia.org/wiki/RNA-Seq&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;RNA-seq&lt;/a&gt; data is quite common nowadays, and there are pretty good &lt;a href=&#34;http://bioconductor.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bioconductor&lt;/a&gt; packages for that: &lt;a href=&#34;http://bioconductor.org/packages/release/bioc/html/limma.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;limma::voom&lt;/a&gt;, &lt;a href=&#34;http://bioconductor.org/packages/release/bioc/html/DESeq2.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DESeq2&lt;/a&gt; &amp;hellip;&lt;/p&gt;
&lt;p&gt;The code for that part is quite simple, being super quick to get a list of de-regulated genes. However, downstream analyses vary a lot depending on the project itself. But I found myself doing the same plots and analyses many times for different project, so I put together a bunch of plots and analyses using code from my colleagues at work (&lt;a href=&#34;http://bioinformatics.sph.harvard.edu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@HSPH bioinformatics core&lt;/a&gt;) and myself.&lt;/p&gt;
&lt;p&gt;There are many possibilities, including QC figures, but the features that seem more interesting are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plot of individual genes using multiple variables from the metadata. This would be an evolution of plotCounts function from DESeq2. Fig1&lt;/li&gt;
&lt;li&gt;plot volcano plots labeling some genes. Fig2&lt;/li&gt;
&lt;li&gt;clustering set of genes to find common patterns expression. Most useful for time seria data. You get as well the list of genes that follows that pattern, so you can use it for functional analysis, for instance. Fig3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;note: maybe some features only available with development version&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/lpantano/mypubs/raw/master/DEG_viz/figure/plots-1.png&#34; alt=&#34;fig1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/lpantano/mypubs/raw/master/DEG_viz/figure/plots-3.png&#34; alt=&#34;fig2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://github.com/lpantano/mypubs/raw/master/DEG_viz/figure/plots-2.png&#34; alt=&#34;fig3&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Package available at &lt;a href=&#34;http://bioconductor.org/packages/devel/bioc/html/DEGreport.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BioC page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The code is available &lt;a href=&#34;https://github.com/lpantano/mypubs/blob/master/DEG_viz&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hope you enjoy!&lt;/p&gt;
&lt;p&gt;Any suggestion and/or issue is welcome &lt;a href=&#34;https://support.bioconductor.org/p/new/post/?tag_val=DEGreport&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;sincerity in bioinformatics: try hard to explain the limitation of your analysis to non-computational researchers&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Maintenance of macrophage transcriptional programs and intestinal homeostasis by epigenetic reader SP140</title>
      <link>http://lpantano.github.io/publication/mehta-2017/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/mehta-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Molecular, phenotypic, and sample-associated data to describe pluripotent stem cell lines and derivatives</title>
      <link>http://lpantano.github.io/publication/daily-2017/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/daily-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comparative analysis of LIN28-RNA binding sites identified at single nucleotide resolution</title>
      <link>http://lpantano.github.io/publication/ransey-2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/ransey-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Empirical comparison of reduced representation bisulfite sequencing and Infinium BeadChip reproducibility and coverage of DNA methylation in humans</title>
      <link>http://lpantano.github.io/publication/carmona-2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/carmona-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Viewing RNA-seq data on the entire human genome</title>
      <link>http://lpantano.github.io/publication/busby-2017/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/busby-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Characterization of the small RNA transcriptome using the bcbio-nextgen python framework</title>
      <link>http://lpantano.github.io/talk/bosc2016/</link>
      <pubDate>Sat, 09 Jul 2016 14:54:17 +0100</pubDate>
      <guid>http://lpantano.github.io/talk/bosc2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title>miRNA Annotation Tools Comparison</title>
      <link>http://lpantano.github.io/post/legacy/2016-03-24-mirna-annotation-tools-comparison/</link>
      <pubDate>Thu, 24 Mar 2016 19:49:01 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2016-03-24-mirna-annotation-tools-comparison/</guid>
      <description>&lt;p&gt;In summary: I will show which is the best miRNA mapping tool. I used several options for this benchmarking:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;miraligner from &lt;a href=&#34;http://github.com/lpantano/seqbuster&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SeqBuster&lt;/a&gt; suit (I am one of the authors)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://bowtie-bio.sourceforge.net/bowtie2/index.shtml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bowtie2&lt;/a&gt; and &lt;a href=&#34;http://bowtie-bio.sourceforge.net/index.shtml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bowtie&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.novocraft.com/main/index.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;novoalign&lt;/a&gt; from novocraft suit&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://algorithms.cnag.cat/wiki/The_GEM_library&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GEM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://arn.ugr.es/srnabench/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;srnabench&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.seqan.de/projects/MicroRazerS.html.&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;microrazer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alexdobin/STAR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;STAR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mirexpress.mbc.nctu.edu.tw/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;miRExpress&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I think that these are the most used, and other not used but good to try them. They were clearly developed for other purposes, but as well, they generate the input of many miRNA pipelines. I just wanted to know how well my tool was doing. The first aim to develop miraligner was to get annotated additions of nucleotides at the end of miRNA sequences, something that is very common in mirna biogenesis: &lt;a href=&#34;http://en.wikipedia.org/wiki/IsomiR&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;isomirs&lt;/a&gt; and often they are missed by short read and fast mappers. I have a &lt;a href=&#34;https://github.com/lpantano/mypubs/tree/master/mirna/mirannotation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;repository&lt;/a&gt; for this kind of things, so anybody can reproduce my results, and check if I did something wrong, or comment on it. In this post I just want to know which tool detects more miRNA, for that I did two main steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;simulate a bunch of miRNAs (isomirs) with my python &lt;a href=&#34;https://github.com/lpantano/seqbuster/blob/master/misc/miRNA.simulator.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;script&lt;/a&gt; that is part of SeqBuster suit. I generated around 10000 sequences. Normally, one small-RNAseq library produces around half million different sequences.&lt;/li&gt;
&lt;li&gt;use only miRBase human precursors as reference genome&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I used default parameter for all, so probably there is a set of parameters that would be better for some tools, but I didn&amp;rsquo;t search for them this time (happy to accept issues to add them). The &lt;a href=&#34;http://rawgit.com/lpantano/mypubs/master/mirna/mirannotation/stats.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;results&lt;/a&gt; are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;miraligner&lt;/strong&gt; and &lt;strong&gt;STAR&lt;/strong&gt; map &lt;strong&gt;more sequences&lt;/strong&gt;. miraligner loses sequences shorter than 15 nt, normally (miRNA) are around 21, and those sequences map to repeat elements&lt;/li&gt;
&lt;li&gt;STAR is the best mapping, but need some parsing to reduce false positive. I think that pipelines should change to this tool.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GEM&lt;/strong&gt; has problems with &lt;strong&gt;additions and nt substitutions&lt;/strong&gt; in many cases, same as novoaligner (I will look at this in the future)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bowtie2/bowtie is the second&lt;/strong&gt; that annotated most (and best)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;microrazer&lt;/strong&gt; has a problem with &lt;strong&gt;mismatches&lt;/strong&gt;, but maybe there is some parameter to trick&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;miRExpress&lt;/strong&gt; with default options only will map perfect matches sequences to precursor, so strongly recommended to allow errors to increase sensibility.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I have to say that the advantage of &lt;a href=&#34;https://github.com/lpantano/seqbuster/wiki/miraligner&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;miraligner&lt;/a&gt; is that it gives you the sequence annotated as miRNA or precursor, and gives you the exactly modifications that sequences have if they are compared to miRBase database. And you could feed the results to my &lt;a href=&#34;https://github.com/lpantano/seqbuster/wiki/isomiRs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;R package&lt;/a&gt; to plot isomers distribution of samples from different groups, and do differential expression analysis with DESeq2, or another tool. I didn&amp;rsquo;t add time consumption because all of them run in a couple of minutes. In my next post I will focus in the the correct annotation of each sequence, and the possible problems with cross-mapping events, when the sequence comes from another regions of the genome but map to miRBase precursor as well [see my previous &lt;a href=&#34;http://lorenapantano.wordpress.com/2013/05/27/mirna-annotation-complex-scenarios/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;post&lt;/a&gt; for more details]. As well I will use STAR with the full genome and see if the mapping continues being the best. In that case I will add a script to SeqBuster to parse the output of STAR for those who can map with STAR (need up to 32G for human genome)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Genomic analyses identify molecular subtypes of pancreatic cancer</title>
      <link>http://lpantano.github.io/publication/bailey-2016/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/bailey-2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Specific small-RNA signatures in the amygdala at premotor and motor stages of Parkinson&#39;s disease revealed by deep sequencing analysis.</title>
      <link>http://lpantano.github.io/publication/pantano-2015/</link>
      <pubDate>Sun, 01 Nov 2015 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/pantano-2015/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The small RNA content of human sperm reveals pseudogene-derived piRNAs complementary to protein-coding genes.</title>
      <link>http://lpantano.github.io/publication/pantano-2015-a/</link>
      <pubDate>Mon, 01 Jun 2015 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/pantano-2015-a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Functional Impact and Evolution of a Novel Human Polymorphic Inversion That Disrupts a Gene and Creates a Fusion Transcript</title>
      <link>http://lpantano.github.io/publication/puig-2015/</link>
      <pubDate>Thu, 01 Jan 2015 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/puig-2015/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Paternal Diet Defines Offspring Chromatin State and Intergenerational Obesity</title>
      <link>http://lpantano.github.io/publication/ost-2014/</link>
      <pubDate>Mon, 01 Dec 2014 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/ost-2014/</guid>
      <description></description>
    </item>
    
    <item>
      <title>InvFEST, a database integrating information of polymorphic inversions in the human genome</title>
      <link>http://lpantano.github.io/publication/martinez-fundichely-2014/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/martinez-fundichely-2014/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Regulation of miRNA strand selection: follow the leader?</title>
      <link>http://lpantano.github.io/publication/meijer-2014/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/meijer-2014/</guid>
      <description></description>
    </item>
    
    <item>
      <title>small RNA abundance [miss-] viz</title>
      <link>http://lpantano.github.io/post/legacy/2013-10-29-small-rna-abundance-miss-viz/</link>
      <pubDate>Tue, 29 Oct 2013 08:05:56 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2013-10-29-small-rna-abundance-miss-viz/</guid>
      <description>&lt;p&gt;My PhD was focused on small RNA sequencing data. I had a problem when I wanted to visualized the amount of small RNAs from the beginning. Here the problem, assume that you have a certain distribution of small RNA sequences abundance:&lt;/p&gt;
&lt;p&gt;seq1: 1500 times&lt;br&gt;
seq2: 3 times&lt;br&gt;
seq3: 2 times&lt;/p&gt;
&lt;p&gt;And you want to show the nucleotide composition of the first nucleotide. You can do it either counting the # of sequences (or abundance) in your set (1505) or the number of unique (different) sequences (3). You result will be very bias depending on that. If you go for the first option, you can obtain:&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/ntabundance11.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;1000px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;and if you go for the second option:&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/ntabundance2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;1000px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;Which is the best option? well, although papers in small RNA data still continue showing the first option, I think that this should be validated some way.&lt;/p&gt;
&lt;p&gt;When using unique sequences (only counting different sequences), you can under-estimated the real signal. In NGS, you can have a lot of noise, that may hide the biological signal using this approach. But, you can get the same, if you use directly the abundance, because if your set contains one sequence that is 90% of the data, you will get always a signal, that may be not important, for instance, ribosomal RNA that is expected to be there.&lt;/p&gt;
&lt;p&gt;One solution is to plot the data according both values: percentage of abundance and percentage of unique sequences. And you can do this for each position and nucleotide.&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/ntabundance3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;1000px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;We can conclude that at position 1, there are few sequences starting with A that are  90 of the data. Also we can see how the 60% of unique sequences have a G at position 10. This helps us to catch any biological signature if it exists, and avoid the misleading information in this kind of figures.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lying factor in figures</title>
      <link>http://lpantano.github.io/post/legacy/2013-08-07-lying-factor-in-figures/</link>
      <pubDate>Wed, 07 Aug 2013 11:36:25 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2013-08-07-lying-factor-in-figures/</guid>
      <description>&lt;p&gt;What is the lying factor in figures?&lt;/p&gt;
&lt;p&gt;It is the ratio between the difference of two numbers and the difference of the visualization of those two numbers. For instance:&lt;/p&gt;
&lt;p&gt;You have two groups, each group is represented by 4 and 2. The difference between 4 and 2 is 2. Since &amp;ldquo;a picture is worth a thousand words&amp;rdquo;, someone decides to represents those groups in a figure (yes, in excel to make it worst):&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/lyingfactor.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;1000px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;That figure shows a difference of 4 between the two groups. Since 4 is twice than 2, we have a lying factor of 2.&lt;/p&gt;
&lt;p&gt;Probably you think that this is not happening anywhere, it is ridiculous. It is, but probably you will find one of these cases in the news every day.&lt;/p&gt;
&lt;p&gt;Moreover, this is happening in science as well. For instance a (Nature) paper which explains how authors are improving a method that analyzes NGS data.&lt;/p&gt;
&lt;p&gt;They visualised a matrix correlation of the data using one method or another (b or c).&lt;/p&gt;
&lt;p&gt;![Screen Shot 2013-08-05 at 12.15.55 PM]({{ site.url }}/assets/screen-shot-2013-08-05-at-12-15-55-pm.png)&lt;/p&gt;
&lt;p&gt;If you only read colours, you won&amp;rsquo;t see much difference, but there is. The problem was to use a different colour scale to show the same type of data. Probably they were produced separately, so the command to produce those figures (probably an R function) had to guess the scale by its own, resulting that 0.89 is equal to 0.75 .&lt;/p&gt;
&lt;p&gt;I leave my post here, and may say: take some time to think about it.&lt;/p&gt;
&lt;p&gt;source:http://dx.doi.org/10.1038/nbt.2596&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>miRNA annotation: complex scenarios</title>
      <link>http://lpantano.github.io/post/legacy/2013-05-27-mirna-annotation-complex-scenarios/</link>
      <pubDate>Mon, 27 May 2013 10:13:02 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2013-05-27-mirna-annotation-complex-scenarios/</guid>
      <description>&lt;p&gt;Everybody who is working with microRNA knows about miRBase, it was the first miRNA catalogue. Everybody is using it to annotate small RNA sequences as miRNA or not. And it is great, and very helpfully&amp;hellip;but there are some cases that we should investigate our results.&lt;/p&gt;
&lt;p&gt;For instance, what happens with miR-1246? it is a recent miRNA, primate specific, detected by sequencing in different studies (1,2,3). The counts related to these sequences are not so high, actually very low after normalization, but still are there. miRBase gives a precursor this region: chr2: 177465708-177465780 [-]&lt;/p&gt;


















&lt;figure  id=&#34;figure-fig-1-mir1246&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/mir1246.png&#34; alt=&#34;Fig 1: mir1246&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig 1: mir1246
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;We see that there is a repeat element (ERV, retrovirus) and also it is a pretty conserved region. Until here, everything allright. But, I realized some time ago, annotating some data that I had, that the mature miRNA annotates in other regions:&lt;/p&gt;
&lt;table border=&#34;1&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;chr:start-end strand&lt;/td&gt;
&lt;td&gt;type&lt;/td&gt;
&lt;td&gt;conservation&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chr13:21,186,304-21,186,473 +&lt;/td&gt;
&lt;td&gt;U2&lt;/td&gt;
&lt;td&gt;human&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chr14:96,850,961-96,851,148 +&lt;/td&gt;
&lt;td&gt;U2&lt;/td&gt;
&lt;td&gt;rhesus&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chr5:157,403,780-157,403,964 -&lt;/td&gt;
&lt;td&gt;U2&lt;/td&gt;
&lt;td&gt;rhesus&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chr6:89,773,226-89,773,409 -&lt;/td&gt;
&lt;td&gt;U2&lt;/td&gt;
&lt;td&gt;rhesus&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chr13:46,948,540-46,948,725 -&lt;/td&gt;
&lt;td&gt;U2&lt;/td&gt;
&lt;td&gt;rhesus&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chr3:127,793,920-127,794,092 -&lt;/td&gt;
&lt;td&gt;U2&lt;/td&gt;
&lt;td&gt;rhesus&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chr2:177,465,708-177,465,780 -&lt;/td&gt;
&lt;td&gt;miR-1246&lt;/td&gt;
&lt;td&gt;rhesus,mouse,dog,elephant&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;All of them are copies of a RNA repeat according RepBase, specifically the snRNA U2 class (150-200 nt). In addition, I got much more reads inside those (extra) locations than inside the annotated precursor (3 orders bigger). Furthermore, all of them had a peak in their coverage profile (fig 2).&lt;/p&gt;


















&lt;figure  id=&#34;figure-fig-2reads-coverage-of-u2&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/u2-3.png&#34; alt=&#34;Fig 2:Reads coverage of U2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig 2:Reads coverage of U2
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;The question that arises now: is this a real miRNA, or a sub-product, or both? with any function? Maybe there is more than one precursor, or maybe it is a miRNA-like snRNA. Moreover, the secondary structure of these U2 is very similar to a miRNA precursor hairpin (fig 3).&lt;/p&gt;


















&lt;figure  id=&#34;figure-fig-3u2-secondary-structure&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/u2-ss-strand.png&#34; alt=&#34;Fig 3:U2 secondary structure&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Fig 3:U2 secondary structure
    &lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;One cause of this annotation could be that the unique precursor conserved beyond primates is the one mentioned in miRBase, while the other U2 locations are primate-specific. Extra analyses should be done to reveal the real nature of this miRNA. Results suggest that, either the miRNA has more than one precursor, or a sub-product, or both.&lt;/p&gt;
&lt;p&gt;As an extra-analysis, I took public data, KO Dicer and control, of HELA cells (GSM769512) to study the dependency od these sequences to DICER. You expect a decrease in the number of counts of miRNA sequences, between control and KO dicer. The exact miRNA sequence decrease 1/3 in KO dicer cells, assuming a Dicer dependency, and take this sequence as a real miRNA. But, we have a lot of other sequences in the U2 regions, but not in the annotated precursor, and only differ in one extra nucleotide (Adenosine) at the beginning (miR-1246: AAUGGAUUUUUGGAGCAGG and U2: &lt;strong&gt;A&lt;/strong&gt;AAUGGAUUUUUGGAGCAGG).This sequence can be annotated as miR-1246 if you allow 1 mismatch in the alignment (the A nt). This sequence had the same counts in normal cells and KO cells, suggesting that sequences from U2 are not Dicer-dependent. Summarizing, we have the mature annotated miRNA mapping in all these positions, and in addition, we have other sequences (one nt longer), that only map in the U2 positions. So, how we can differentiate what proportion of sequences comes from the precursors and what comes from the other positions? Well, one possibility is to detect the precursor by PCR in your samples, to assume that at least it is there, or try to see whether the coverage in the different locations makes sense more with one scenario or another&amp;hellip;Or maybe it is not a big deal, you have this small RNA, the question is whether it has any regulatory function or not.&lt;/p&gt;
&lt;p&gt;From here, we may agree that it is better to double-check what is happening when annotating small RNAs, because there are many possibilities to take a wrong conclusion if you only believe in a preliminary analysis. Nowadays, data is increasing a lot, and scientists need to make a bunch of assumptions to obtain something, but be careful with those assumptions (indeed, they are needed to evolve in science) because you may be missing something else or getting something wrong or wasting your time with experiments to corroborate your computational results.&lt;/p&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;p&gt;[1] PMID:18583537&lt;br&gt;
&amp;ldquo;MicroRNA discovery and profiling in human embryonic stem cells by deep sequencing of small RNA libraries&amp;rdquo;&lt;br&gt;
Bar M, Wyman SK, Fritz BR, Qi J, Garg KS, Parkin RK, Kroh EM, Bendoraite A, Mitchell PS, Nelson AM, Ruzzo WL, Ware C, Radich JP, Gentleman R, Ruohola-Baker H, Tewari M&lt;br&gt;
Stem Cells. 26:2496-2505(2008).&lt;br&gt;
[2] PMID:20300190&lt;br&gt;
&amp;ldquo;Characterization of the Melanoma miRNAome by Deep Sequencing&amp;rdquo;&lt;br&gt;
Stark MS, Tyagi S, Nancarrow DJ, Boyle GM, Cook AL, Whiteman DC, Parsons PG, Schmidt C, Sturm RA, Hayward NK&lt;br&gt;
PLoS One. 5:e9685(2010).&lt;br&gt;
[3] PMID:20459774&lt;br&gt;
&amp;ldquo;Ultra-high throughput sequencing-based small RNA discovery and discrete statistical biomarker analysis in a collection of cervical tumours and matched controls&amp;rdquo;&lt;br&gt;
Witten D, Tibshirani R, Gu SG, Fire A, Lui WO&lt;br&gt;
BMC Biol. 8:58(2010).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A highly expressed miR-101 isomiR is a functional silencing small RNA.</title>
      <link>http://lpantano.github.io/publication/llorens-2013/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/llorens-2013/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Microarray and deep sequencing cross-platform analysis of the mirRNome and isomiR variation in response to epidermal growth factor.</title>
      <link>http://lpantano.github.io/publication/llorens-2013-a/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/llorens-2013-a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>visualizing small RNA mapping complexity</title>
      <link>http://lpantano.github.io/post/legacy/2012-09-18-visualizing-small-rna-mapping-complexity/</link>
      <pubDate>Tue, 18 Sep 2012 12:10:24 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2012-09-18-visualizing-small-rna-mapping-complexity/</guid>
      <description>&lt;p&gt;I spent all my PhD working with small RNA sequences data. The main problem was, always those sequences that map in multiple locations, also denominated ambiguous sequences. From the very beginning, this made that pipelines remove this kind of sequences from the analysis, because you cannot assign them a unique location in the genome. But these sequences are interesting to study, since many of them change in size, for instance. This complexity is due to repeats in the genome and the scenario I am talking about here it is shown in the following figure: ![]({{ site.url }}/assets/example1.png)&lt;/p&gt;
&lt;p&gt;Each color it would be a different sRNA, and the lines show the locations of each sRNA. There are location shared by some of the sRNAs, and you can easily transform this into a network of vertexes and edges, where vertexes are locations and edges, are their relationship coming from the sRNAs inside them. In this case it would generate three circles connected between them. And that it was I did with a real data set. I used &lt;a href=&#34;http://igraph.sourceforge.net/&#34; title=&#34;igraph&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;igraph&lt;/a&gt; in R to represent this with the help of this great &lt;a href=&#34;http://nsaunders.wordpress.com/2010/04/21/experiments-with-igraph/&#34; title=&#34;igraph tutorial&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tutorial&lt;/a&gt;. The result is:&lt;/p&gt;

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 &lt;figure  &gt;
   &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
     &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/network.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;500px&#34; /&gt;&lt;/div&gt;
   &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;It is very easy to detect high complexity regions, where locations are connected because some sRNAs map to anywhere else. From here, you can add more information, as the average size of the sRNAs inside each location, or the expression (red: low, yellow:high).   ![]({{ site.baseurl }}/assets/net-exp-3.png &amp;ldquo;network of sRNA complexity&amp;rdquo;) In a quick view you can check the complexity of your small RNA data and the expression associated. The code is published at &lt;a href=&#34;http://rpubs.com/lpantano/1719&#34; title=&#34;sRNA mappability&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rpub repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing science is also cool @polychart</title>
      <link>http://lpantano.github.io/post/legacy/2012-08-14-visualizing-science-is-also-cool-polychart/</link>
      <pubDate>Tue, 14 Aug 2012 15:28:12 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2012-08-14-visualizing-science-is-also-cool-polychart/</guid>
      <description>&lt;p&gt;One of my interest in science is finding new ways to visualize Big Data. Scientist are used to work with static visualization, that of course, is wonderful in the majority of the case. But it wouldn&amp;rsquo;t be better dynamic visualization for exploration? Play with your data, explore, and finally when you get that great figure that tell you everything you was looking for, you can export it to an image portable format.&lt;/p&gt;
&lt;p&gt;I played many time with javascript/HTML5 resources, but are no so easy to implement if you are not an expert, and some times, huge data makes difficult the easy interaction. Well, recently I found &lt;a href=&#34;http://polychart.com/&#34; title=&#34;polychart&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Polychart&lt;/a&gt;, is still in beta version, but I am using one of the feature they provide: Graph builder. And this is how it looks like after loading a file with 5000 rows and 37 columns:&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/polychart.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;1000px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;You can make different type of charts, like boxplot, barplot, piechart (although aren&amp;rsquo;t well considered) etc. Also, you can customize titles and transform data. Quick complete for a beta version.&lt;/p&gt;
&lt;p&gt;Finally but not less important, it is free for academics. :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bionformatics evolution 2005-2012</title>
      <link>http://lpantano.github.io/post/legacy/2012-04-13-bionformatics-evolution-2005-2012/</link>
      <pubDate>Fri, 13 Apr 2012 10:45:07 -0400</pubDate>
      <guid>http://lpantano.github.io/post/legacy/2012-04-13-bionformatics-evolution-2005-2012/</guid>
      <description>&lt;p&gt;How much keywords in &lt;a href=&#34;http://en.wikipedia.org/wiki/Bioinformatics&#34; title=&#34;bioinformatics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bioinformatics&lt;/a&gt; has changed in the past 7 years?&lt;br&gt;
I did a small and quick experiment. I took the abstract of the papers published in Bioinformatics during Jan-2005 and during Jan-2012. Then I represented the words according to their frequency with the &lt;a href=&#34;http://www.wordle.net/&#34; title=&#34;wordle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wordle&lt;/a&gt; tool. And the result was:&lt;/p&gt;


















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/jan2005bioinformatics.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;500px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;



















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;images/jan2012bioinformatics.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable width=&#34;500px&#34; /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

&lt;p&gt;What is main difference? There are new concepts, of course, but the main difference is the size of the word DATA and the word METHOD, as it happens in the real world, data increased a lot, so we put it much more in our work, and we need a lof of new methods, so we highlight this in our work.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Pathogenic Mechanism in Huntington&#39;s Disease Involves Small CAG-Repeated RNAs with Neurotoxic Activity.</title>
      <link>http://lpantano.github.io/publication/banez-coronel-2012/</link>
      <pubDate>Wed, 01 Feb 2012 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/banez-coronel-2012/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A non-biased framework for the annotation and classification of the non-miRNA small RNA transcriptome.</title>
      <link>http://lpantano.github.io/publication/pantano-2011/</link>
      <pubDate>Tue, 01 Nov 2011 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/pantano-2011/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A myriad of miRNA variants in control and Huntington&#39;s disease brain regions detected by massively parallel sequencing</title>
      <link>http://lpantano.github.io/publication/marti-2010/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/marti-2010/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SeqBuster, a bioinformatic tool for the processing and analysis of small RNAs datasets, reveals ubiquitous miRNA modifications in human embryonic cells</title>
      <link>http://lpantano.github.io/publication/pantano-2010/</link>
      <pubDate>Fri, 01 Jan 2010 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/pantano-2010/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Fibroblast-derived induced pluripotent stem cells show no common retroviral vector insertions.</title>
      <link>http://lpantano.github.io/publication/varas-2009/</link>
      <pubDate>Sun, 01 Feb 2009 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/varas-2009/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Identification of Copy Number Variants Defining Genomic Differences among Major Human Groups</title>
      <link>http://lpantano.github.io/publication/armengol-2009/</link>
      <pubDate>Thu, 01 Jan 2009 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/armengol-2009/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ProSeeK: A web server for MLPA probe design</title>
      <link>http://lpantano.github.io/publication/pantano-2008/</link>
      <pubDate>Tue, 01 Jan 2008 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/pantano-2008/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Highlights from the Third International Society for Computational Biology Student Council Symposium at the Fifteenth Annual International Conference on Intelligent Systems for Molecular Biology</title>
      <link>http://lpantano.github.io/publication/grynberg-2007/</link>
      <pubDate>Mon, 01 Jan 2007 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/grynberg-2007/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Genome assembly comparison identifies structural variants in the human genome.</title>
      <link>http://lpantano.github.io/publication/khaja-2006/</link>
      <pubDate>Sun, 01 Jan 2006 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/publication/khaja-2006/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
