<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bioinformatics | My bits</title>
    <link>http://lpantano.github.io/tag/bioinformatics/</link>
      <atom:link href="http://lpantano.github.io/tag/bioinformatics/index.xml" rel="self" type="application/rss+xml" />
    <description>Bioinformatics</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 04 Feb 2026 12:00:00 -0400</lastBuildDate>
    <image>
      <url>http://lpantano.github.io/media/icon_hu_518ecd45d9711c5b.png</url>
      <title>Bioinformatics</title>
      <link>http://lpantano.github.io/tag/bioinformatics/</link>
    </image>
    
    <item>
      <title>Multi-Lab Genomics Data Sharing with IGV, S3, and GitHub Actions</title>
      <link>http://lpantano.github.io/post/2026/2026-02-04-igv-aws-github/</link>
      <pubDate>Wed, 04 Feb 2026 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2026/2026-02-04-igv-aws-github/</guid>
      <description>&lt;p&gt;Most collaborative genomics projects fail not because the science is hard, but because managing and sharing heterogeneous data across collaborators is hard.&lt;/p&gt;
&lt;p&gt;We solved this problem by composing existing tools instead of building custom code. Here&amp;rsquo;s how.&lt;/p&gt;
&lt;p&gt;TLDR:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lpantano/igv-web-genomics-platform/tree/main&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub available&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://youtu.be/_qPsqCyFsgg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks to &lt;a href=&#34;https://www.linkedin.com/in/ruitong-li-6a83a0149/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ruitong Li&lt;/a&gt; for contributing to the project.&lt;/p&gt;
&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Your collaborators send differential expression results from their single-cell RNA and ATAC-seq experiments. Some work is in mouse, some in human. Your task: find the genes they identified as significant, check the signal in all other experiments, and compare across species—all from a single interface.&lt;/p&gt;
&lt;p&gt;Without infrastructure, this means emailing files, manually looking up gene coordinates, translating between genome builds (mouse to human), and checking signal experiment by experiment. It doesn&amp;rsquo;t scale. Collaborators wait. Nobody wins.&lt;/p&gt;
&lt;h2 id=&#34;the-solution-composition-over-complexity&#34;&gt;The Solution: Composition Over Complexity&lt;/h2&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Architecture diagram showing data flow from collaborators through AWS S3, GitHub Actions, CloudFront, Lambda authentication, and into the IGV Web App&#34; srcset=&#34;
               /post/2026/2026-02-04-igv-aws-github/architecture-diagram_hu_7ba5888c32fe0497.webp 400w,
               /post/2026/2026-02-04-igv-aws-github/architecture-diagram_hu_94c5bb3785ab1a65.webp 760w,
               /post/2026/2026-02-04-igv-aws-github/architecture-diagram_hu_520328a28afa5f33.webp 1200w&#34;
               src=&#34;http://lpantano.github.io/post/2026/2026-02-04-igv-aws-github/architecture-diagram_hu_7ba5888c32fe0497.webp&#34;
               width=&#34;615&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We focused on three decisions:&lt;/p&gt;
&lt;h3 id=&#34;1-choose-tools-that-do-80-of-the-work&#34;&gt;1. Choose Tools That Do 80% of the Work&lt;/h3&gt;
&lt;p&gt;We selected &lt;a href=&#34;https://igv.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IGV (Integrative Genomics Viewer)&lt;/a&gt;—the web app version. It&amp;rsquo;s a professional genome browser designed for exactly what we needed: jumping between genes, loading multiple data types, fast interactive navigation. We didn&amp;rsquo;t build visualization code; IGV handles that elegantly.&lt;/p&gt;
&lt;h3 id=&#34;2-standardize-everything-into-compatible-formats&#34;&gt;2. Standardize Everything Into Compatible Formats&lt;/h3&gt;
&lt;p&gt;IGV natively understands a few core formats: BED files (genomic regions with annotations), BigWig files (signal tracks), and narrowPeak files (ATAC-seq peaks). Our collaborators send data in CSV format from DESeq2.&lt;/p&gt;
&lt;p&gt;We built an automated pipeline that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Detects file types&lt;/strong&gt;: ATAC-seq BigWig/BED files, RNA-seq CSV files&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Converts DESeq2 results&lt;/strong&gt; → color-coded BED files with four-tier significance coloring:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Red&lt;/strong&gt;: Up-regulated (p &amp;lt; 0.05 &amp;amp; log2FC &amp;gt; 1.5)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Blue&lt;/strong&gt;: Down-regulated (p &amp;lt; 0.05 &amp;amp; log2FC &amp;lt; -1.5)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Orange&lt;/strong&gt;: Significant but low fold change (p &amp;lt; 0.05 &amp;amp; |log2FC| &amp;lt; 1.5)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gray&lt;/strong&gt;: Not significant&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Translates cross-species data&lt;/strong&gt;: If the DESeq2 results are from mouse, the pipeline maps mouse genes to human orthologs and converts coordinates to hg38—automatically&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leaves compatible formats as-is&lt;/strong&gt;: ATAC-seq peaks and BigWig files pass through unchanged&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The script scans project folders, identifies each file type, applies the appropriate transformation, and generates a track registry describing everything for IGV.&lt;/p&gt;
&lt;h3 id=&#34;3-automate-everything-including-deployment&#34;&gt;3. Automate Everything, Including Deployment&lt;/h3&gt;
&lt;p&gt;We organized data hierarchically: three main research projects, with experiments nested inside. When you open IGV, you see a project modal. Click a project, and you get a searchable table of all its experiments—grouped by experiment ID or data type.&lt;/p&gt;
&lt;p&gt;Everything lives on AWS S3. Lambda@Edge functions enforce password authentication at the CloudFront edge—only authorized collaborators can access the data. Passwords are shared securely with the team.&lt;/p&gt;
&lt;p&gt;For continuous updates, we use GitHub Actions. Set it to run daily or trigger manually. When new data arrives in the S3 data folder, the action:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scans all projects for new CSV files&lt;/li&gt;
&lt;li&gt;Runs the conversion script on anything new (skips already-converted files)&lt;/li&gt;
&lt;li&gt;Updates the track registry (CSV and JSON files)&lt;/li&gt;
&lt;li&gt;Syncs metadata back to S3&lt;/li&gt;
&lt;li&gt;Fixes MIME types for BigWig files&lt;/li&gt;
&lt;li&gt;Invalidates the CloudFront cache&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Within seconds, new data is live in IGV. No manual deployment. No command-line expertise required. The whole team benefits from new data immediately.&lt;/p&gt;
&lt;h2 id=&#34;technical-implementation&#34;&gt;Technical Implementation&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s what makes this work technically:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Organization:&lt;/strong&gt;
Three projects (&lt;code&gt;project1&lt;/code&gt;, &lt;code&gt;project2&lt;/code&gt;, &lt;code&gt;project3&lt;/code&gt;), each containing experiment subfolders with BED, BigWig, or CSV files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Automation Script&lt;/strong&gt; (&lt;a href=&#34;https://github.com/hbc/app-igv-skinpo1/blob/main/scripts/automate_igv_tracks.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;automate_igv_tracks.py&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Auto-scans the entire data directory recursively&lt;/li&gt;
&lt;li&gt;Identifies ATAC-seq files (.bed, .narrowPeak, .bw) and RNA-seq CSV files&lt;/li&gt;
&lt;li&gt;Converts new CSV files to BED using the &lt;code&gt;create_igv_bed.py&lt;/code&gt; converter (skips if BED already exists)&lt;/li&gt;
&lt;li&gt;Generates &lt;code&gt;project_name.csv&lt;/code&gt; with track metadata (type, URL, display options)&lt;/li&gt;
&lt;li&gt;Generates &lt;code&gt;project_name.json&lt;/code&gt; with IGV configuration&lt;/li&gt;
&lt;li&gt;Updates the central &lt;code&gt;trackRegistry.json&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Optional: &lt;code&gt;--dry-run&lt;/code&gt; flag to preview changes before applying&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Format Conversion&lt;/strong&gt; (&lt;a href=&#34;https://github.com/hbc/app-igv-skinpo1/blob/main/scripts/create_igv_bed.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;create_igv_bed.py&lt;/a&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reads DESeq2 output (gene_id, log2FoldChange, p-value columns)&lt;/li&gt;
&lt;li&gt;Species detection: Automatically recognizes mouse or human (looks for MGI gene symbols or Ensembl IDs)&lt;/li&gt;
&lt;li&gt;Species translation: Maps mouse genes to human orthologs and converts coordinates&lt;/li&gt;
&lt;li&gt;Creates color-coded BED files with biological meaning (red=up, blue=down, orange=borderline)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Deployment to Production:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;S3 bucket stores all data and configuration files&lt;/li&gt;
&lt;li&gt;CloudFront CDN sits in front for fast global access&lt;/li&gt;
&lt;li&gt;Lambda@Edge enforces authentication at edge nodes globally&lt;/li&gt;
&lt;li&gt;GitHub Actions runs daily: mounts S3 folder, runs automation, syncs results back, invalidates CloudFront cache&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Access Control:&lt;/strong&gt;
Basic HTTP authentication (username/password) enforced at CloudFront. No backend needed. Users authenticate once in their browser, then browse the genome naturally.&lt;/p&gt;
&lt;h2 id=&#34;why-this-approach-works&#34;&gt;Why This Approach Works&lt;/h2&gt;
&lt;p&gt;We didn&amp;rsquo;t have a development team or a large budget. So we focused on composition: choosing tools that solve 80% of the problem, automating the 20% they don&amp;rsquo;t handle.&lt;/p&gt;
&lt;p&gt;This approach has three advantages:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It scales.&lt;/strong&gt; As new collaborators join and new data arrives, the same automation handles it. No new code needed. The GitHub Action handles everything.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It&amp;rsquo;s maintainable.&lt;/strong&gt; The GitHub Action runs on a schedule you set. The conversion script is pure Python—transparent and understandable. Version control means you can roll back if something breaks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It&amp;rsquo;s focused on the science.&lt;/strong&gt; Researchers spend time analyzing genes, not wrestling with deployment pipelines. They add a CSV file to a folder. Within minutes, it&amp;rsquo;s browsable alongside all their collaborators&amp;rsquo; data.&lt;/p&gt;
&lt;h2 id=&#34;the-lesson&#34;&gt;The Lesson&lt;/h2&gt;
&lt;p&gt;You don&amp;rsquo;t need a development team to build research infrastructure. You need:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clear problem definition (one gene, all experiments)&lt;/li&gt;
&lt;li&gt;Existing tools that solve most of it (IGV for browsing)&lt;/li&gt;
&lt;li&gt;Automation to handle the gaps (Python script + GitHub Actions)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you have a similar challenge—multiple collaborators, heterogeneous data, limited resources—this approach works. Look for the existing tool that&amp;rsquo;s 80% of your solution. Build automation for the 20% it doesn&amp;rsquo;t cover. Deploy it once, then let it run.&lt;/p&gt;
&lt;p&gt;The full code is available on &lt;a href=&#34;https://github.com/hbc/app-igv-skinpo1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;. It includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Python automation pipeline&lt;/li&gt;
&lt;li&gt;AWS deployment scripts&lt;/li&gt;
&lt;li&gt;GitHub Actions workflow&lt;/li&gt;
&lt;li&gt;Complete documentation for adding new datasets&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limitations-and-future-work&#34;&gt;Limitations and Future Work&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cross-species support&lt;/strong&gt;: Currently handles mouse→human translation for RNA-seq only. Other species would need custom ortholog mappings. Other data types need additional code.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;User management&lt;/strong&gt;: Today uses a shared password. For multiple independent users, consider Amazon Cognito or similar.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These aren&amp;rsquo;t blockers for most research groups, but they&amp;rsquo;re worth noting if you&amp;rsquo;re adapting this approach.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Systematic Paper Reviews with Claude Custom Commands</title>
      <link>http://lpantano.github.io/post/2026/2026-01-28-claude-custom-commands-paper-review/</link>
      <pubDate>Wed, 28 Jan 2026 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2026/2026-01-28-claude-custom-commands-paper-review/</guid>
      <description>&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
      &lt;iframe allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen&#34; loading=&#34;eager&#34; referrerpolicy=&#34;strict-origin-when-cross-origin&#34; src=&#34;https://www.youtube.com/embed/YZry3CwDwAw?autoplay=0&amp;amp;controls=1&amp;amp;end=0&amp;amp;loop=0&amp;amp;mute=0&amp;amp;start=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; title=&#34;YouTube video&#34;&gt;&lt;/iframe&gt;
    &lt;/div&gt;

&lt;p&gt;&lt;em&gt;Note: Claude now calls custom commands &amp;ldquo;skills&amp;rdquo; - the functionality is identical, just renamed. This post uses the original &amp;ldquo;custom commands&amp;rdquo; terminology from the video.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;the-problem-inconsistent-paper-reviews&#34;&gt;The Problem: Inconsistent Paper Reviews&lt;/h2&gt;
&lt;p&gt;I review hundreds of scientific papers for the &lt;a href=&#34;https://healthintegrityproject.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Health Integrity Project&lt;/a&gt;. We evaluate health claims—things you hear everywhere, like &amp;ldquo;Red raspberry leaf shortens labor&amp;rdquo;—and determine if scientific evidence supports them.&lt;/p&gt;
&lt;p&gt;The challenge? Consistency.&lt;/p&gt;
&lt;p&gt;Manual reviews take 30 minutes to 2 hours per paper. I might check for conflicts of interest thoroughly in one review, then forget in the next. Focus on statistical methods in one paper, skip bias assessment in another. My criteria shift paper to paper.&lt;/p&gt;
&lt;p&gt;This inconsistency doesn&amp;rsquo;t just waste time—it undermines scientific validity. If evaluation criteria change between papers, the entire project loses credibility.&lt;/p&gt;
&lt;h2 id=&#34;the-solution-claude-custom-commands&#34;&gt;The Solution: Claude Custom Commands&lt;/h2&gt;
&lt;p&gt;Claude custom commands tell the AI model exactly how to handle a specific task. I created a command that runs the same evaluation workflow every single time.&lt;/p&gt;
&lt;p&gt;The workflow asks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are there conflicts of interest?&lt;/li&gt;
&lt;li&gt;Is this a valid study type (not narrative reviews)?&lt;/li&gt;
&lt;li&gt;Is the control group adequate?&lt;/li&gt;
&lt;li&gt;What biases exist?&lt;/li&gt;
&lt;li&gt;Do results align with the claim?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each paper goes through identical steps. Nothing gets skipped.&lt;/p&gt;
&lt;h2 id=&#34;how-it-works&#34;&gt;How It Works&lt;/h2&gt;
&lt;p&gt;A custom command is a markdown file in your project folder (&lt;code&gt;.claude/commands/&lt;/code&gt;). Mine is called &lt;code&gt;review-paper.md&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;basic-structure&#34;&gt;Basic Structure&lt;/h3&gt;
&lt;p&gt;Every custom command has three parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt;: What you provide&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Task&lt;/strong&gt;: What Claude should do&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output format&lt;/strong&gt;: How results should look&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here&amp;rsquo;s the minimal markdown structure:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;# Command Name

## Input
- Item 1 (e.g., paper location)
- Item 2 (e.g., claim to evaluate)

## Task
Step-by-step instructions for Claude to follow

## Output Format
How you want results structured
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;my-paper-review-workflow&#34;&gt;My Paper Review Workflow&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;## Step 1: Validation Screen
- Check conflict of interest
- Identify study type
- Flag narrative reviews or meta-analyses
- Output: VALID or INVALID with reasons

## Step 2: Quality Assessment
- Evaluate control groups
- Assess statistical methods
- Identify biases
- Output: Quality rating with evidence

## Step 3: Result Alignment
- Compare study results to claim
- Determine if supporting or contradicting
- Output: Category recommendation
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;real-example-raspberry-leaf-study&#34;&gt;Real Example: Raspberry Leaf Study&lt;/h2&gt;
&lt;p&gt;I run the command: &lt;code&gt;/review-paper&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Claude asks for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paper location&lt;/li&gt;
&lt;li&gt;Claim being evaluated&lt;/li&gt;
&lt;li&gt;Paper position (supporting or contradicting)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I provide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Paper: &lt;code&gt;raspberry-study.pdf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Claim: &amp;ldquo;Red raspberry leaf shortens labor and helps induce birth&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Position: Supporting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Claude starts the evaluation:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1 Results:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Funding: Company involvement noted, but primary funding independent&lt;/li&gt;
&lt;li&gt;Study type: Human clinical trial (valid)&lt;/li&gt;
&lt;li&gt;No narrative meta-analysis&lt;/li&gt;
&lt;li&gt;Status: Proceed to quality check&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 2 Results:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Control group: Present&lt;/li&gt;
&lt;li&gt;Statistical methods: Adequate sample size, appropriate tests&lt;/li&gt;
&lt;li&gt;Biases: Selection bias possible (self-reported outcomes)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 3 Results:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Study results: No significant difference in labor duration&lt;/li&gt;
&lt;li&gt;Alignment with claim: CONTRADICTS&lt;/li&gt;
&lt;li&gt;Category: Misinformation (claim unsupported by results)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At each step, I can interact: &amp;ldquo;Dig deeper into selection bias&amp;rdquo; or &amp;ldquo;Show exact quote about labor duration from paper.&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;beyond-paper-reviews&#34;&gt;Beyond Paper Reviews&lt;/h2&gt;
&lt;p&gt;Custom commands work for any repeated workflow.&lt;/p&gt;
&lt;p&gt;Example for bioinformatics:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;Command: /optimize-nextflow

Input: Pipeline directory

Task:
1. Analyze resource usage from execution reports
2. Calculate actual vs requested CPU/memory
3. Ignore failed jobs
4. Generate updated resource config
5. Optional: Update nextflow.config

Output: Resource optimization recommendations
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Time savings&lt;/strong&gt;: Reviews that took 1-2 hours now take 30 minutes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Same questions, same order, every paper.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thoroughness&lt;/strong&gt;: Nothing gets forgotten or skipped.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transparency&lt;/strong&gt;: The workflow is documented and repeatable.&lt;/p&gt;
&lt;p&gt;The custom command doesn&amp;rsquo;t replace my judgment—it retrieves information and ensures I evaluate every paper the same way. I still make final decisions. I still dig deeper when needed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What custom commands can&amp;rsquo;t do&lt;/strong&gt;: Make subjective quality judgments, understand context outside the paper, or catch every nuance in complex statistical methods. They work best for structured, repeatable workflows where the steps are clear.&lt;/p&gt;
&lt;p&gt;But I never miss conflict of interest checks again. I never forget to assess control groups. The baseline evaluation happens consistently.&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Find a workflow you repeat frequently&lt;/li&gt;
&lt;li&gt;Document the steps&lt;/li&gt;
&lt;li&gt;Define input, task, and output format&lt;/li&gt;
&lt;li&gt;Create a markdown file in &lt;code&gt;.claude/commands/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Test and refine&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Start simple. Even basic workflows benefit from automation.&lt;/p&gt;
&lt;p&gt;The goal isn&amp;rsquo;t to hand everything to AI. It&amp;rsquo;s to ensure your systematic processes stay systematic.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Resources:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://healthintegrityproject.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Health Integrity Project&lt;/a&gt; - Evidence-based health claim evaluation&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://code.claude.com/docs/en/skills&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Claude Custom Commands/skills Documentation&lt;/a&gt; - How to create your own commands&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://healthintegrityproject.org/workflow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Health Integrity Review Workflow&lt;/a&gt; - Our paper evaluation process&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Have you tried custom commands for your repeated workflows? What tasks would benefit from systematic automation in your work?&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bringing IGV webapp to Your Cloud Workspace in Seqera</title>
      <link>http://lpantano.github.io/post/2026/2026-01-16-igv-cloud-visualization/</link>
      <pubDate>Fri, 16 Jan 2026 12:00:00 -0400</pubDate>
      <guid>http://lpantano.github.io/post/2026/2026-01-16-igv-cloud-visualization/</guid>
      <description>&lt;p&gt;You just ran a genomic pipeline that generated 50GB of BAM files in the cloud. Now you need to check alignment quality. Do you really have to download everything to run IGV locally? Switch virtual machines to load the files? Write code to generate static visuals?&lt;/p&gt;
&lt;p&gt;This integration brings IGV directly to your cloud workspace with &lt;strong&gt;automatic track discovery&lt;/strong&gt;. It scans your storage, finds all genomic files, and presents them in a ready-to-load menu. No downloads, no file paths, no manual configuration.&lt;/p&gt;
&lt;h2 id=&#34;the-workflow-gap&#34;&gt;The Workflow Gap&lt;/h2&gt;
&lt;p&gt;Analysis happens in the cloud. Fast compute, scalable storage, pipelines that finish overnight.&lt;/p&gt;
&lt;p&gt;Visualization happens separately or requires coding. Manual downloads or transfers, disk space constraints, waiting for transfers to complete, changing environments.&lt;/p&gt;
&lt;p&gt;This gap slows iteration. It wastes time. And it&amp;rsquo;s fixable.&lt;/p&gt;
&lt;h2 id=&#34;what-cloud-native-visualization-looks-like&#34;&gt;What Cloud-Native Visualization Looks Like&lt;/h2&gt;
&lt;p&gt;I built an integration that runs IGV as a web app directly in Seqera workspaces. It connects to the same cloud storage your pipelines write to. It automatically discovers all genomic files. Zero downloads, zero manual file loading.&lt;/p&gt;
&lt;p&gt;Other solutions exist—desktop IGV in Studios or Python notebooks for programmatic visualization. These work, but they&amp;rsquo;re not seamless. Desktop IGV still requires manual file path configuration. Notebooks require coding for every view. This approach eliminates both friction points.&lt;/p&gt;
&lt;h2 id=&#34;how-it-works&#34;&gt;How It Works&lt;/h2&gt;
&lt;p&gt;The container combines IGV web app with Seqera&amp;rsquo;s connect-client. The connect-client uses FUSE to mount cloud storage, making remote files appear local to IGV.&lt;/p&gt;
&lt;p&gt;A startup script &lt;strong&gt;scans&lt;/strong&gt; mounted directories for genomic files—BAM, CRAM, VCF, BED, BigWig, anything IGV can read. It detects file formats, checks for index files, and generates a track catalog. IGV reads this catalog and populates a custom &amp;ldquo;Auto-discovered Tracks&amp;rdquo; menu.&lt;/p&gt;
&lt;p&gt;The visualization tool comes to where data already lives.&lt;/p&gt;
&lt;h2 id=&#34;what-this-looks-like-in-practice&#34;&gt;What This Looks Like in Practice&lt;/h2&gt;
&lt;p&gt;Launch the IGV Studio from your Seqera interface. Your browser opens with the IGV web app.&lt;/p&gt;
&lt;p&gt;Click Tracks → Auto-discovered Tracks. See a table of all your BAM files, VCF variants, coverage tracks—everything in your mounted storage.&lt;/p&gt;
&lt;p&gt;Click to load. Instant visualization.&lt;/p&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Skip the download/coding wait.&lt;/strong&gt; Checking alignments after a pipeline run no longer means waiting to transfer data or coding.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stop duplicating storage.&lt;/strong&gt; No local copies means hundreds of GB saved per researcher.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Share results faster.&lt;/strong&gt; Send a browser URL instead of transferring massive files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Onboard easier.&lt;/strong&gt; New team members don&amp;rsquo;t need complex local setups. They click a link and start viewing data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Improve reproducibility.&lt;/strong&gt; Everyone views the same authoritative data source in cloud storage, not their own potentially outdated local copies.&lt;/p&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Important context:&lt;/strong&gt; This solution is specifically for Seqera Platform users. If you&amp;rsquo;re using other platforms like Terra, AnVIL, Galaxy, or DNAnexus, they have their own approaches to interactive visualization. This implementation leverages Seqera&amp;rsquo;s Studios feature and connect-client architecture.&lt;/p&gt;
&lt;p&gt;The full implementation is open source in the &lt;a href=&#34;https://github.com/lpantano/custom-studios-examples/tree/master/igv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seqera custom studios examples repository&lt;/a&gt;. You&amp;rsquo;ll find:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complete Dockerfile with multi-stage build&lt;/li&gt;
&lt;li&gt;Automatic track discovery script&lt;/li&gt;
&lt;li&gt;Deployment documentation&lt;/li&gt;
&lt;li&gt;Configuration examples&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Maturity note:&lt;/strong&gt; This is a proof of concept tested on several datasets. It demonstrates the pattern and should help you get started, but expect to adapt it for production use. Test thoroughly with your own data and file structures.&lt;/p&gt;
&lt;p&gt;The code is customizable. Adapt the track discovery logic for your file naming conventions. Change the reference genome. Add authentication if needed.&lt;/p&gt;
&lt;h2 id=&#34;the-broader-pattern&#34;&gt;The Broader Pattern&lt;/h2&gt;
&lt;p&gt;Cloud-native analysis means rethinking entire workflows, not just moving compute. Bringing visualization to cloud data is part of that shift.&lt;/p&gt;
&lt;p&gt;Other platforms (Terra, AnVIL) mount cloud storage for interactive apps too. What makes this useful is the &lt;strong&gt;automatic track discovery&lt;/strong&gt;—most solutions require manual file paths.&lt;/p&gt;
&lt;p&gt;The less time you spend moving data around, the more time you spend understanding it.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Robinson JT, et al. (2011). Integrative genomics viewer. Nature Biotechnology 29(1):24-26. &lt;a href=&#34;https://www.nature.com/articles/nbt.1754&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DOI: 10.1038/nbt.1754&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://igv.org/doc/webapp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IGV Web App Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.seqera.io/platform-cloud/studios/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seqera Studios Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lpantano/custom-studios-examples/tree/master/igv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Implementation Repository&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Single-Cell RNA-Seq Analysis Reports</title>
      <link>http://lpantano.github.io/portfolio/singlecell-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/portfolio/singlecell-reports/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;A collection of code templates and training materials for performing downstream analysis following single-cell RNA preprocessing. This repository provides standardized workflows for researchers working with scRNA-seq data, from quality assessment to differential expression.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View Documentation →&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub Repository →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Quality Assessment&lt;/strong&gt;: Templates for evaluating scRNA and scATAC data quality&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration Analysis&lt;/strong&gt;: Workflows for combining multiple samples with batch effect correction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Differential Expression&lt;/strong&gt;: Multiple approaches including pseudobulk analysis via DESeq2 and MAST methodology&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compositional Analysis&lt;/strong&gt;: Methods for examining cell-type abundance changes across conditions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gene Imputation&lt;/strong&gt;: Techniques using ALRA and MAGIC algorithms to address data sparsity&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipeline Integration&lt;/strong&gt;: Support for nf-core scrnaseq pipeline outputs and standalone Cell Ranger processing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built primarily in R with supporting shell scripts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for single-cell data handling and analysis&lt;/li&gt;
&lt;li&gt;DESeq2 for differential expression analysis&lt;/li&gt;
&lt;li&gt;Harmony for batch effect correction&lt;/li&gt;
&lt;li&gt;nf-core scrnaseq pipeline integration&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for reproducible reports&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates for common scRNA-seq tasks&lt;/li&gt;
&lt;li&gt;Training materials and documentation&lt;/li&gt;
&lt;li&gt;Standardized workflows following best practices&lt;/li&gt;
&lt;li&gt;Integration with popular preprocessing pipelines&lt;/li&gt;
&lt;li&gt;Examples for both scRNA-seq and scATAC-seq data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Templates are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Single-cell RNA-seq analysis requires specialized knowledge and tools. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces the learning curve for new single-cell researchers&lt;/li&gt;
&lt;li&gt;Provides validated workflows following community best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible analysis through standardized templates&lt;/li&gt;
&lt;li&gt;Supports multiple experimental designs and research questions&lt;/li&gt;
&lt;li&gt;Integrates seamlessly with popular preprocessing pipelines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt; or explore the &lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Single-Cell RNA-Seq Analysis Reports</title>
      <link>http://lpantano.github.io/project/singlecell-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/project/singlecell-reports/</guid>
      <description>&lt;p&gt;A collection of code templates and training materials for performing downstream analysis following single-cell RNA preprocessing. This repository provides standardized workflows for researchers working with scRNA-seq data, from quality assessment to differential expression.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View Documentation →&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GitHub Repository →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Quality Assessment&lt;/strong&gt;: Templates for evaluating scRNA and scATAC data quality&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration Analysis&lt;/strong&gt;: Workflows for combining multiple samples with batch effect correction&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Differential Expression&lt;/strong&gt;: Multiple approaches including pseudobulk analysis via DESeq2 and MAST methodology&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compositional Analysis&lt;/strong&gt;: Methods for examining cell-type abundance changes across conditions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gene Imputation&lt;/strong&gt;: Techniques using ALRA and MAGIC algorithms to address data sparsity&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pipeline Integration&lt;/strong&gt;: Support for nf-core scrnaseq pipeline outputs and standalone Cell Ranger processing&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built primarily in R with supporting shell scripts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for single-cell data handling and analysis&lt;/li&gt;
&lt;li&gt;DESeq2 for differential expression analysis&lt;/li&gt;
&lt;li&gt;Harmony for batch effect correction&lt;/li&gt;
&lt;li&gt;nf-core scrnaseq pipeline integration&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for reproducible reports&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates for common scRNA-seq tasks&lt;/li&gt;
&lt;li&gt;Training materials and documentation&lt;/li&gt;
&lt;li&gt;Standardized workflows following best practices&lt;/li&gt;
&lt;li&gt;Integration with popular preprocessing pipelines&lt;/li&gt;
&lt;li&gt;Examples for both scRNA-seq and scATAC-seq data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Templates are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Single-cell RNA-seq analysis requires specialized knowledge and tools. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces the learning curve for new single-cell researchers&lt;/li&gt;
&lt;li&gt;Provides validated workflows following community best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible analysis through standardized templates&lt;/li&gt;
&lt;li&gt;Supports multiple experimental designs and research questions&lt;/li&gt;
&lt;li&gt;Integrates seamlessly with popular preprocessing pipelines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/singlecell-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt; or explore the &lt;a href=&#34;https://bcbio.github.io/singlecell-reports/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Transcriptomics Analysis Reports</title>
      <link>http://lpantano.github.io/portfolio/spatial-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/portfolio/spatial-reports/</guid>
      <description>&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;p&gt;A template repository providing analysis workflows for spatial single-cell transcriptomics data across multiple experimental platforms and analytical packages. This project offers researchers standardized pipelines for quality control, clustering, and cell-type annotation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View on GitHub →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-Platform Support&lt;/strong&gt;: Templates for COSMX and Visium[HD] spatial transcriptomics platforms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quality Control Pipelines&lt;/strong&gt;: Comprehensive QC assessment workflows for data validation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering Workflows&lt;/strong&gt;: Spatial clustering using Banksy and other established tools&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cell-Type Annotation&lt;/strong&gt;: Integration with spacexr for cell-type identification and differential expression&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reproducible Environment&lt;/strong&gt;: RStudio Projects with renv package management for dependency control&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built entirely in R with integration of leading bioinformatics tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for Visium object handling&lt;/li&gt;
&lt;li&gt;Banksy for spatial clustering analysis&lt;/li&gt;
&lt;li&gt;spacexr for cell-type identification&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for report generation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates&lt;/li&gt;
&lt;li&gt;Downloadable test data for learning and validation&lt;/li&gt;
&lt;li&gt;Dependency installation scripts&lt;/li&gt;
&lt;li&gt;Quick-start documentation for RStudio users&lt;/li&gt;
&lt;li&gt;Standardized workflows across different spatial platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Projects are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Spatial transcriptomics generates complex data requiring specialized analysis approaches. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces setup time for new spatial transcriptomics projects&lt;/li&gt;
&lt;li&gt;Provides validated workflows following best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible research through standardized templates&lt;/li&gt;
&lt;li&gt;Lowers the barrier to entry for spatial data analysis&lt;/li&gt;
&lt;li&gt;Maintains consistency across different experimental platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spatial Transcriptomics Analysis Reports</title>
      <link>http://lpantano.github.io/project/spatial-reports/</link>
      <pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://lpantano.github.io/project/spatial-reports/</guid>
      <description>&lt;p&gt;A template repository providing analysis workflows for spatial single-cell transcriptomics data across multiple experimental platforms and analytical packages. This project offers researchers standardized pipelines for quality control, clustering, and cell-type annotation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;View on GitHub →&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multi-Platform Support&lt;/strong&gt;: Templates for COSMX and Visium[HD] spatial transcriptomics platforms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quality Control Pipelines&lt;/strong&gt;: Comprehensive QC assessment workflows for data validation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clustering Workflows&lt;/strong&gt;: Spatial clustering using Banksy and other established tools&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cell-Type Annotation&lt;/strong&gt;: Integration with spacexr for cell-type identification and differential expression&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reproducible Environment&lt;/strong&gt;: RStudio Projects with renv package management for dependency control&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;technical-stack&#34;&gt;Technical Stack&lt;/h2&gt;
&lt;p&gt;Built entirely in R with integration of leading bioinformatics tools:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Seurat for Visium object handling&lt;/li&gt;
&lt;li&gt;Banksy for spatial clustering analysis&lt;/li&gt;
&lt;li&gt;spacexr for cell-type identification&lt;/li&gt;
&lt;li&gt;Quarto and R Markdown for report generation&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-it-provides&#34;&gt;What It Provides&lt;/h2&gt;
&lt;p&gt;The repository includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ready-to-use analysis templates&lt;/li&gt;
&lt;li&gt;Downloadable test data for learning and validation&lt;/li&gt;
&lt;li&gt;Dependency installation scripts&lt;/li&gt;
&lt;li&gt;Quick-start documentation for RStudio users&lt;/li&gt;
&lt;li&gt;Standardized workflows across different spatial platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;development-status&#34;&gt;Development Status&lt;/h2&gt;
&lt;p&gt;Projects are labeled with revision tiers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stable&lt;/strong&gt;: Fully tested and production-ready&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alpha&lt;/strong&gt;: Functional but requires additional testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft&lt;/strong&gt;: Under active development, may need manual parameter tuning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-this-matters&#34;&gt;Why This Matters&lt;/h2&gt;
&lt;p&gt;Spatial transcriptomics generates complex data requiring specialized analysis approaches. This project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduces setup time for new spatial transcriptomics projects&lt;/li&gt;
&lt;li&gt;Provides validated workflows following best practices&lt;/li&gt;
&lt;li&gt;Enables reproducible research through standardized templates&lt;/li&gt;
&lt;li&gt;Lowers the barrier to entry for spatial data analysis&lt;/li&gt;
&lt;li&gt;Maintains consistency across different experimental platforms&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more information or to contribute, visit the &lt;a href=&#34;https://github.com/bcbio/spatial-reports&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
